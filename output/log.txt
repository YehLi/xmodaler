[07/07 15:42:16] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:42:17] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:42:17] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:42:17] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  #FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  #ANNO_FOLDER:  '/export1/dataset/open_source/mscoco'
  FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  #VOCAB: '/export1/dataset/open_source/mscoco/coco_vocabulary.txt'
  VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  #VAL_ANNFILE: '/export1/dataset/open_source/mscoco/captions_val5k.json'
  #TEST_ANNFILE: '/export1/dataset/open_source/mscoco/captions_test5k.json'
  VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:42:17] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: D:/export/dataset/mscoco_open_source
  FEATS_FOLDER: D:/export/dataset/mscoco_open_source/features/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: D:/export/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: D:/export/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: D:/export/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:42:17] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:42:17] xl.utils.env INFO: Using a generated random seed 17718925
[07/07 15:44:05] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:44:07] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:44:07] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:44:07] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:44:07] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:44:07] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:44:07] xl.utils.env INFO: Using a generated random seed 7444915
[07/07 15:45:43] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:45:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:45:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:45:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:45:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:45:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:45:45] xl.utils.env INFO: Using a generated random seed 45197980
[07/07 15:45:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 15:45:48] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 15:45:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 15:45:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:45:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:45:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:45:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:45:53] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 15:45:53] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 15:55:00] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:55:01] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:55:01] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:55:01] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:55:01] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:55:01] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:55:01] xl.utils.env INFO: Using a generated random seed 1496450
[07/07 15:55:03] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 15:55:03] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 15:55:05] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 15:55:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:55:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:55:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:55:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:55:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 15:55:07] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:25:36] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:25:37] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:25:37] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:25:37] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:25:37] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:25:37] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:25:37] xl.utils.env INFO: Using a generated random seed 37995181
[07/07 16:25:39] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:25:40] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:25:41] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:25:41] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:25:41] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:25:41] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:25:41] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:25:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:25:44] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:27:20] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:27:21] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:27:21] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:27:21] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:27:21] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:27:21] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:27:21] xl.utils.env INFO: Using a generated random seed 21732096
[07/07 16:27:23] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:27:23] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:27:25] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:27:25] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:27:25] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:27:25] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:27:25] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:27:27] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:27:27] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:28:09] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:28:10] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:28:10] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:28:10] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:28:10] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:28:10] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:28:10] xl.utils.env INFO: Using a generated random seed 11028974
[07/07 16:28:12] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:28:13] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:28:14] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:28:14] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:28:14] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:28:14] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:28:14] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:28:16] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:28:16] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:29:16] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:29:17] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:29:17] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:29:17] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:29:17] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:29:17] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:29:17] xl.utils.env INFO: Using a generated random seed 18060370
[07/07 16:29:19] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:29:20] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:29:21] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:29:21] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:29:21] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:29:21] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:29:21] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:29:23] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:29:23] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:30:00] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:30:01] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:30:01] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:30:01] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:30:01] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:30:01] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:30:01] xl.utils.env INFO: Using a generated random seed 1451853
[07/07 16:30:03] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:30:03] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:30:05] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:30:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:30:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:30:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:30:07] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:30:53] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:30:54] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:30:54] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:30:54] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:30:54] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:30:54] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:30:54] xl.utils.env INFO: Using a generated random seed 54469016
[07/07 16:30:56] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:30:56] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:30:57] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:30:57] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:57] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:30:58] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:58] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:31:00] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:31:00] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:33:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:33:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:33:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:33:27] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:33:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:33:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:33:27] xl.utils.env INFO: Using a generated random seed 27902023
[07/07 16:33:29] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:33:30] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:33:31] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:33:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:33:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:33:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:33:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:33:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:33:33] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:36:32] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:36:33] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:36:33] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:36:33] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:36:33] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:36:33] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:36:33] xl.utils.env INFO: Using a generated random seed 33659654
[07/07 16:36:35] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:36:36] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:36:38] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:36:38] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:36:38] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:36:38] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:36:38] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:36:40] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:36:40] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:43:50] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:43:51] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:43:51] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:43:51] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:43:51] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:43:51] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:43:51] xl.utils.env INFO: Using a generated random seed 51589570
[07/07 16:43:53] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:43:53] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:43:55] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:43:55] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:43:55] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:43:55] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:43:55] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:43:57] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:43:57] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:46:39] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 60, in forward
    g_tfeats = layer_module(g_tfeats, vfeats, ext_g_tmasks, ext_vmasks, history_states_i)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 403, in forward
    x, _ = self.self_attn(lang_feats, lang_attention_mask, t_history_states)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 142, in forward
    self_output, attention_probs = self.self(input_tensor, attention_mask, history_states)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 73, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (96) must match the size of tensor b (32) at non-singleton dimension 0
[07/07 16:46:39] xl.engine.hooks INFO: Total training time: 0:02:41 (0:02:41 on hooks)
[07/07 16:46:39] xl.utils.events INFO:  iter: 0  total_loss: 9.573  data_time: 0.0229  lr: 0.0005  max_mem: 392M
[07/07 16:47:01] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:47:02] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:47:02] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:47:02] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:47:02] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:47:02] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:47:02] xl.utils.env INFO: Using a generated random seed 2783598
[07/07 16:47:04] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:47:05] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:47:06] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:47:06] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:47:06] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:47:06] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:47:06] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:47:08] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:47:08] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:51:19] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:51:20] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:51:20] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:51:20] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:51:20] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:51:20] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:51:20] xl.utils.env INFO: Using a generated random seed 20566708
[07/07 16:51:22] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:51:22] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:51:24] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:51:24] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:51:24] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:51:24] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:51:24] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:51:26] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:51:26] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:42:44] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:42:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:42:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:42:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:42:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:42:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:42:45] xl.utils.env INFO: Using a generated random seed 45872878
[07/07 17:42:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:42:48] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:42:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:42:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:42:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:42:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:42:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:42:51] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:42:51] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:42:57] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/transformer_enc_dec.py", line 107, in _forward
    decoder_out = self.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 60, in forward
    history_states = [None] * self.g_layers
TypeError: can't multiply sequence by non-int of type 'ModuleList'
[07/07 17:42:57] xl.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[07/07 17:42:57] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 177M
[07/07 17:44:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:44:49] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:44:49] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:44:49] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:44:49] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:44:49] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:44:49] xl.utils.env INFO: Using a generated random seed 49541614
[07/07 17:44:51] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:44:51] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:44:53] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:44:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:44:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:44:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:44:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:44:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:44:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:44:55] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/transformer_enc_dec.py", line 107, in _forward
    decoder_out = self.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 64, in forward
    history_states[i] = torch.cat([history_states[i], g_tfeats], dim=1)
TypeError: expected Tensor as element 0 in argument 0, but got NoneType
[07/07 17:44:55] xl.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[07/07 17:44:55] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 177M
[07/07 17:45:14] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:45:15] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:45:15] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:45:15] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:45:15] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:45:15] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:45:15] xl.utils.env INFO: Using a generated random seed 15904307
[07/07 17:45:17] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:45:18] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:45:19] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:45:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:45:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:45:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:45:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:45:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:45:21] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:46:41] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 64, in forward
    history_states[i] = torch.cat([history_states[i], g_tfeats], dim=1)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
[07/07 17:46:41] xl.engine.hooks INFO: Total training time: 0:01:19 (0:01:19 on hooks)
[07/07 17:46:41] xl.utils.events INFO:  iter: 0  total_loss: 9.579  data_time: 0.0211  lr: 0.0005  max_mem: 392M
[07/07 17:49:43] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:49:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:49:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:49:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:49:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:49:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:49:45] xl.utils.env INFO: Using a generated random seed 45313252
[07/07 17:49:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:49:47] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:49:48] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:49:48] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:49:48] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:49:48] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:49:48] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:49:50] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:49:50] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:50:39] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:50:40] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:50:40] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:50:40] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:50:40] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:50:40] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:50:40] xl.utils.env INFO: Using a generated random seed 40860894
[07/07 17:50:42] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:50:43] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:50:44] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:50:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:50:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:50:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:50:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:50:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:50:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:50:59] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:51:00] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:51:00] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:51:00] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:51:00] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:51:00] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:51:00] xl.utils.env INFO: Using a generated random seed 952328
[07/07 17:51:02] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:51:03] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:51:04] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:51:04] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:51:04] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:51:04] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:51:04] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:51:06] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:51:06] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:51:12] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 56, in forward
    shape[1] = 0
TypeError: 'torch.Size' object does not support item assignment
[07/07 17:51:12] xl.engine.hooks INFO: Total training time: 0:00:05 (0:00:05 on hooks)
[07/07 17:51:12] xl.utils.events INFO:  iter: 0  total_loss: 9.629  data_time: 0.0220  lr: 0.0005  max_mem: 392M
[07/07 17:54:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:54:05] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:54:05] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:54:05] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:54:05] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:54:05] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:54:05] xl.utils.env INFO: Using a generated random seed 5491337
[07/07 17:54:07] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:54:07] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:54:09] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:54:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:54:11] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:54:16] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 56, in forward
    shape[1] = 0
TypeError: 'torch.Size' object does not support item assignment
[07/07 17:54:16] xl.engine.hooks INFO: Total training time: 0:00:04 (0:00:04 on hooks)
[07/07 17:54:16] xl.utils.events INFO:  iter: 0  total_loss: 9.656  data_time: 0.0230  lr: 0.0005  max_mem: 392M
[07/07 17:54:25] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:54:26] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:54:26] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:54:26] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:54:26] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:54:26] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:54:26] xl.utils.env INFO: Using a generated random seed 26703062
[07/07 17:54:28] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:54:28] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:54:30] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:54:30] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:30] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:30] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:30] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:32] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:54:32] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:55:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:55:48] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:55:48] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:55:48] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:55:48] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:55:48] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:55:48] xl.utils.env INFO: Using a generated random seed 48756976
[07/07 17:55:50] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:55:50] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:55:52] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:55:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:55:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:55:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:55:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:55:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:55:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:58:02] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 58, in forward
    history_states = [g_tfeats.new(torch.as_tensor(shape))] * self.num_generation_layers
TypeError: expected TensorOptions(dtype=float, device=cuda, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=long int, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))
[07/07 17:58:02] xl.engine.hooks INFO: Total training time: 0:02:07 (0:02:07 on hooks)
[07/07 17:58:02] xl.utils.events INFO:  iter: 0  total_loss: 9.643  data_time: 0.0272  lr: 0.0005  max_mem: 392M
[07/07 17:58:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:58:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:58:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:58:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:58:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:58:41] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:58:41] xl.utils.env INFO: Using a generated random seed 41308281
[07/07 17:58:43] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:58:43] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:58:44] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:58:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:58:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:58:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:58:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:58:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:58:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:59:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:59:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:59:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:59:27] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:59:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:59:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:59:27] xl.utils.env INFO: Using a generated random seed 27499603
[07/07 17:59:29] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:59:29] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:59:31] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:59:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:59:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:59:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:59:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:59:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:59:33] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 18:02:43] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 64, in forward
    history_states[i] = torch.cat([history_states[i], g_tfeats], dim=1)
RuntimeError: Sizes of tensors must match except in dimension 0. Got 96 and 32 (The offending index is 0)
[07/07 18:02:43] xl.engine.hooks INFO: Total training time: 0:03:09 (0:03:09 on hooks)
[07/07 18:02:43] xl.utils.events INFO:  iter: 0  total_loss: 9.449  data_time: 0.0278  lr: 0.0005  max_mem: 392M
[07/07 18:13:41] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 18:13:42] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 18:13:42] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 18:13:42] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 18:13:42] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 18:13:42] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 18:13:42] xl.utils.env INFO: Using a generated random seed 42333456
[07/07 18:13:44] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 18:13:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 18:13:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 18:13:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 18:13:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 18:13:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 18:13:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 18:13:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 18:13:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:03:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:03:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:03:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:03:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:03:42] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:03:42] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:03:42] xl.utils.env INFO: Using a generated random seed 42065574
[07/07 19:03:43] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:03:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:03:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:03:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:03:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:03:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:03:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:03:47] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:03:47] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:08:50] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:08:52] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:08:52] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:08:52] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:08:52] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:08:52] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:08:52] xl.utils.env INFO: Using a generated random seed 52618761
[07/07 19:08:55] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:08:55] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:08:57] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:08:57] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:08:57] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:08:57] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:08:57] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:08:59] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:08:59] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:09:48] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:09:49] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:09:49] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:09:49] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:09:49] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:09:49] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:09:49] xl.utils.env INFO: Using a generated random seed 49780000
[07/07 19:09:51] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:09:51] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:09:53] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:09:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:09:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:09:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:09:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:09:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:09:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:10:14] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:10:15] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:10:15] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:10:15] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:10:15] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:10:15] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:10:15] xl.utils.env INFO: Using a generated random seed 15811702
[07/07 19:10:17] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:10:17] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:10:19] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:10:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:10:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:10:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:10:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:10:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:10:21] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:13:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:13:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:13:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:13:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:13:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:13:41] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:13:41] xl.utils.env INFO: Using a generated random seed 41775957
[07/07 19:13:44] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:13:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:13:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:13:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:13:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:13:46] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:13:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:13:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:13:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:18:18] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:18:19] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:18:19] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:18:19] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:18:19] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:18:19] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:18:19] xl.utils.env INFO: Using a generated random seed 19767747
[07/07 19:18:21] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:18:21] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:18:23] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:18:23] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:18:23] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:18:23] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:18:23] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:18:25] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:18:25] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:19:56] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:19:57] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:19:57] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:19:57] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:19:57] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:19:57] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:19:57] xl.utils.env INFO: Using a generated random seed 57552343
[07/07 19:19:59] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:19:59] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:20:01] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:20:01] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:20:01] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:20:01] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:20:01] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:20:03] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:20:03] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 21:01:21] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 21:01:22] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 21:01:22] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 21:01:22] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 21:01:22] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 21:01:22] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 21:01:22] xl.utils.env INFO: Using a generated random seed 22510294
[07/07 21:01:24] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 21:01:24] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 21:01:26] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 21:01:26] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:01:26] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:01:26] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:01:26] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:01:28] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 21:01:28] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 21:05:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 21:05:42] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 21:05:42] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 21:05:42] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 21:05:42] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 21:05:42] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 21:05:42] xl.utils.env INFO: Using a generated random seed 42116839
[07/07 21:05:44] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 21:05:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 21:05:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 21:05:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:05:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:05:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:05:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:05:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 21:05:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:21:20] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/updown_decoder.py", line 86, in forward
    input1 = torch.cat([h2_tm1, global_feats, wt], 1)
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
[07/07 22:21:25] xl.engine.hooks INFO: Total training time: 0:00:06 (0:00:06 on hooks)
[07/07 22:21:25] xl.utils.events INFO:  iter: 0  total_loss: 7.981  data_time: 0.0220  lr: 0.0005  max_mem: 936M
[07/07 22:22:07] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:22:09] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:22:09] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:22:09] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 22:22:09] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:22:09] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:22:09] xl.utils.env INFO: Using a generated random seed 9095487
[07/07 22:22:11] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:22:11] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 22:22:12] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 22:22:12] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:22:12] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:22:12] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:22:12] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:22:14] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:22:14] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:23:01] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/updown_decoder.py", line 86, in forward
    input1 = torch.cat([h2_tm1, global_feats, wt], 1)
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
[07/07 22:23:01] xl.engine.hooks INFO: Total training time: 0:00:29 (0:00:29 on hooks)
[07/07 22:23:01] xl.utils.events INFO:  iter: 0  total_loss: 8.003  data_time: 0.0215  lr: 0.0005  max_mem: 936M
[07/07 22:23:45] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:23:46] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:23:46] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:23:46] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 22:23:46] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:23:46] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:23:46] xl.utils.env INFO: Using a generated random seed 46513386
[07/07 22:23:48] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:23:48] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 22:23:50] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 22:23:50] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:23:50] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:23:50] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:23:50] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:23:52] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:23:52] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:24:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:24:48] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:24:48] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:24:48] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 22:24:48] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:24:48] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:24:48] xl.utils.env INFO: Using a generated random seed 48519501
[07/07 22:24:50] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:24:50] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 22:24:52] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 22:24:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:24:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:24:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:24:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:24:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:24:54] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:54:12] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:54:14] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:54:14] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/salstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:54:14] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/salstm.yaml:
_BASE_: "base_caption.yaml"

MODEL: 
  ENCODER: 'Encoder'
  SALSTM:
    ATT_EMBED_SIZE: 512
    ATT_EMBED_DROPOUT: 0.0
  


[07/07 22:54:14] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: SALSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  SALSTM:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:54:14] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:54:14] xl.utils.env INFO: Using a generated random seed 14270082
[07/07 22:54:58] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:55:00] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:55:00] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/salstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:55:00] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/salstm.yaml:
_BASE_: "base_caption.yaml"

MODEL: 
  ENCODER: 'Encoder'
  SALSTM:
    ATT_EMBED_SIZE: 512
    ATT_EMBED_DROPOUT: 0.0
  


[07/07 22:55:00] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: SALSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  SALSTM:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:55:00] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:55:00] xl.utils.env INFO: Using a generated random seed 219328
[07/07 22:56:26] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): SALSTMDecoder(
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
    (lstm): LSTMCell(2048, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:56:27] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 22:56:28] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 22:56:28] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 22:56:28] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 22:56:28] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 22:56:28] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 22:56:31] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:56:32] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:02:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:02:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:02:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:02:27] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 23:02:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:02:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:02:27] xl.utils.env INFO: Using a generated random seed 27878500
[07/07 23:02:31] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:02:31] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:02:33] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:02:33] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:02:33] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:02:33] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:02:33] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:02:35] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:02:35] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:05:39] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:05:40] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:05:40] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:05:40] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:05:40] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:05:40] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:05:40] xl.utils.env INFO: Using a generated random seed 40636974
[07/07 23:05:45] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:05:45] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:05:46] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:05:46] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:05:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:05:46] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:05:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:05:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:05:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:12:30] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:12:32] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:12:32] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:12:32] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:12:32] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:12:32] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:12:32] xl.utils.env INFO: Using a generated random seed 32361198
[07/07 23:14:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:14:47] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:14:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:14:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:14:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:14:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:14:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:16:02] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:16:06] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:20:03] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:20:04] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:20:04] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:20:04] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:20:04] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:20:04] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:20:04] xl.utils.env INFO: Using a generated random seed 4855251
[07/07 23:20:07] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:20:07] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:20:09] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:20:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:20:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:20:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:20:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:20:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:20:19] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:20:34] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:20:36] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:20:36] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:20:36] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:20:36] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:20:36] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:20:36] xl.utils.env INFO: Using a generated random seed 36223141
[07/07 23:22:40] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:22:41] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:22:42] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:22:42] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:22:42] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:22:42] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:22:42] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:22:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:22:44] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:23:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:23:05] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:23:05] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:23:05] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:23:05] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:23:05] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:23:05] xl.utils.env INFO: Using a generated random seed 5714030
[07/07 23:23:09] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:23:09] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:23:10] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:23:10] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:23:10] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:23:10] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:23:10] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:23:13] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:23:13] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:24:20] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:24:21] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:24:21] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:24:21] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 23:24:21] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:24:21] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:24:21] xl.utils.env INFO: Using a generated random seed 21690657
[07/07 23:24:25] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:24:25] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:24:27] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:24:27] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:27] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:27] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:27] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:29] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:24:29] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:24:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:24:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:24:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:24:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 23:24:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:24:41] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:24:41] xl.utils.env INFO: Using a generated random seed 41938792
[07/07 23:24:46] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:24:47] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:24:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:24:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:51] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:24:51] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:28:05] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:28:06] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:28:06] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/salstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:28:06] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/salstm.yaml:
_BASE_: "base_caption.yaml"

MODEL: 
  ENCODER: 'Encoder'
  SALSTM:
    ATT_EMBED_SIZE: 512
    ATT_EMBED_DROPOUT: 0.0
  


[07/07 23:28:06] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: SALSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  SALSTM:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:28:06] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:28:06] xl.utils.env INFO: Using a generated random seed 6763652
[07/07 23:28:10] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): SALSTMDecoder(
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
    (lstm): LSTMCell(2048, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:28:11] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:28:11] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:28:11] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:28:11] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:28:11] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:28:11] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:28:13] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:28:13] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:28:37] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:28:38] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:28:38] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/mplstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:28:38] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/mplstm.yaml:
_BASE_: "base_caption.yaml"

MODEL:
  DECODER: 'MPLSTMDecoder'
  


[07/07 23:28:38] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: MPLSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:28:38] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:28:38] xl.utils.env INFO: Using a generated random seed 38995075
[07/07 23:28:42] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): MPLSTMDecoder(
    (lstm): LSTMCell(1024, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:28:43] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:28:44] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:28:44] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:28:44] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:28:44] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:28:44] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:28:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:28:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:28:47] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/rnn_att_enc_dec.py", line 40, in _forward
    inputs = self.decoder.preprocess(inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/mplstm_decoder.py", line 38, in preprocess
    gv_feat = batched_inputs[kfg.GLOBAL_FEATS]
KeyError: 'GLOBAL_FEATS'
[07/07 23:28:47] xl.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[07/07 23:28:47] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 88M
[07/07 23:30:21] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:30:22] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:30:22] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/mplstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:30:22] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/mplstm.yaml:
_BASE_: "base_caption.yaml"

MODEL:
  DECODER: 'MPLSTMDecoder'
  


[07/07 23:30:22] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: MPLSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:30:22] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:30:22] xl.utils.env INFO: Using a generated random seed 22682734
[07/07 23:30:26] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): MPLSTMDecoder(
    (lstm): LSTMCell(1024, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:30:27] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:30:27] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:30:27] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:30:27] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:30:27] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:30:27] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:30:29] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:30:29] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:30:32] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/rnn_att_enc_dec.py", line 40, in _forward
    inputs = self.decoder.preprocess(inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/mplstm_decoder.py", line 38, in preprocess
    gv_feat = batched_inputs[kfg.GLOBAL_FEATS]
KeyError: 'GLOBAL_FEATS'
[07/07 23:30:32] xl.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[07/07 23:30:32] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 88M
[07/07 23:30:57] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:30:59] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:30:59] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/mplstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:30:59] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/mplstm.yaml:
_BASE_: "base_caption.yaml"

MODEL:
  ENCODER: 'UpDownEncoder'
  DECODER: 'MPLSTMDecoder'
  


[07/07 23:30:59] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: MPLSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:30:59] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:30:59] xl.utils.env INFO: Using a generated random seed 59135708
[07/07 23:31:05] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): MPLSTMDecoder(
    (lstm): LSTMCell(1024, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:31:06] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:31:06] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:31:06] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:31:06] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:31:06] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:31:06] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:31:08] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:31:08] xl.engine.train_loop INFO: Starting training from iteration 0
