[07/05 17:43:54] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 17:43:55] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 17:43:55] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 17:43:55] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 17:43:55] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 17:43:55] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 17:43:55] xl.utils.env INFO: Using a generated random seed 55920979
[07/05 17:44:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 17:44:28] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 17:44:28] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 17:44:28] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 17:44:28] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 17:44:28] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 17:44:28] xl.utils.env INFO: Using a generated random seed 28094158
[07/05 17:46:50] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 17:46:51] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 17:46:51] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 17:46:51] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 17:46:51] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 17:46:51] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 17:46:51] xl.utils.env INFO: Using a generated random seed 52031591
[07/05 17:46:58] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 17:47:02] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 17:47:04] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 17:47:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:47:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:47:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:47:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:47:54] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 17:47:55] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 17:47:55] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 17:47:55] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 17:47:55] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 17:47:55] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 17:47:55] xl.utils.env INFO: Using a generated random seed 55810571
[07/05 17:48:27] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 17:48:27] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 17:48:29] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 17:48:29] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:48:29] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:48:29] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:48:29] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:48:58] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 17:48:58] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 17:49:57] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 17:49:58] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 17:49:58] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 17:49:58] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 17:49:58] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 17:49:58] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 17:49:58] xl.utils.env INFO: Using a generated random seed 58986147
[07/05 17:50:44] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 17:50:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 17:50:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 17:50:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:50:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:50:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:50:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:50:52] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 17:50:52] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 17:53:56] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 17:53:58] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 17:53:58] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 17:53:58] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 17:53:58] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 17:53:58] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 17:53:58] xl.utils.env INFO: Using a generated random seed 58187677
[07/05 17:54:02] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 17:54:02] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 17:54:04] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 17:54:04] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:54:04] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:54:04] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 17:54:04] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 17:54:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 17:54:11] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 18:04:13] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 18:04:14] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 18:04:14] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 18:04:14] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 18:04:14] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 18:04:14] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 18:04:14] xl.utils.env INFO: Using a generated random seed 14839561
[07/05 18:04:28] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 18:04:29] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 18:04:30] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 18:04:30] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 18:04:30] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 18:04:30] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 18:04:30] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 18:04:38] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 18:04:38] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 18:05:10] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 28, in run_step
    bs_outputs_dict = self.model(data, use_beam_search=False, output_sents=False)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 70, in forward
    batched_inputs = self.preprocess_batch(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 136, in preprocess_batch
    ids = np.expand_dims(batched_inputs[kfg.IDS], axis=1)
TypeError: list indices must be integers or slices, not str
[07/05 18:05:18] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 18:05:20] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 18:05:20] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 18:05:20] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 18:05:20] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 18:05:20] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 18:05:20] xl.utils.env INFO: Using a generated random seed 20243064
[07/05 18:05:24] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 18:05:24] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 18:05:25] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 18:05:25] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 18:05:25] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 18:05:25] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 18:05:25] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 18:05:32] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 18:05:32] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 18:07:43] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 18:07:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 18:07:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 18:07:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 18:07:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 18:07:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 18:07:45] xl.utils.env INFO: Using a generated random seed 45231279
[07/05 18:11:35] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 18:11:35] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 18:11:36] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 18:11:36] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 18:11:36] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 18:11:36] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 18:11:36] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 18:11:45] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 18:11:45] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 20:55:52] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 32, in run_step
    data[kfg.DECODE_BY_SAMPLE] = True
TypeError: list indices must be integers or slices, not str
[07/05 20:56:07] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 20:56:08] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 20:56:08] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 20:56:08] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 20:56:08] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 20:56:08] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 20:56:08] xl.utils.env INFO: Using a generated random seed 8537837
[07/05 20:58:24] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 20:58:24] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 20:58:26] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 20:58:26] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 20:58:26] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 20:58:26] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 20:58:26] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 20:58:35] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 20:58:35] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:10:08] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:10:09] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:10:09] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:10:09] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:10:09] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:10:09] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:10:09] xl.utils.env INFO: Using a generated random seed 9847949
[07/05 21:10:14] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:10:14] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:10:15] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:10:15] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:10:15] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:10:15] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:10:15] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:10:22] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:10:22] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:11:45] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 36, in run_step
    outputs_dict = self.model(data, use_beam_search=False, output_sents=False, use_preprocess=False)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 75, in forward
    return self.greedy_decode(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 155, in greedy_decode
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/greedy_decoder.py", line 20, in _forward
    ve_out = model.visual_embed(batched_inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/embedding/visual_embed.py", line 64, in forward
    embeddings = self.embeddings(feats)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 96, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 1847, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`
[07/05 21:11:45] xl.engine.hooks INFO: Total training time: 0:01:22 (0:00:00 on hooks)
[07/05 21:11:45] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 214M
[07/05 21:12:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:12:05] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:12:05] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:12:05] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:12:05] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:12:05] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:12:05] xl.utils.env INFO: Using a generated random seed 5670424
[07/05 21:12:09] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:12:10] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:12:12] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:12:12] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:12:12] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:12:12] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:12:12] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:12:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:12:21] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:13:02] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 36, in run_step
    outputs_dict = self.model(data, use_beam_search=False, output_sents=False, use_preprocess=False)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 75, in forward
    return self.greedy_decode(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 155, in greedy_decode
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/greedy_decoder.py", line 20, in _forward
    ve_out = model.visual_embed(batched_inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/embedding/visual_embed.py", line 64, in forward
    embeddings = self.embeddings(feats)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 96, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 1847, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`
[07/05 21:13:02] xl.engine.hooks INFO: Total training time: 0:00:41 (0:00:00 on hooks)
[07/05 21:13:02] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 214M
[07/05 21:13:09] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:13:10] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:13:10] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:13:10] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:13:10] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:13:10] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:13:10] xl.utils.env INFO: Using a generated random seed 10322440
[07/05 21:13:13] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:13:14] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:13:15] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:13:15] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:13:15] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:13:15] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:13:15] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:13:22] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:13:22] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:15:08] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:15:09] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:15:09] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:15:09] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:15:09] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:15:09] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:15:09] xl.utils.env INFO: Using a generated random seed 9341371
[07/05 21:15:36] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:15:36] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:15:38] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:15:38] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:15:38] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:15:38] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:15:38] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:15:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:15:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:23:34] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:23:35] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:23:35] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:23:35] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:23:35] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:23:35] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:23:35] xl.utils.env INFO: Using a generated random seed 35953285
[07/05 21:23:37] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:23:38] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:23:39] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:23:39] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:23:39] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:23:39] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:23:39] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:23:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:23:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:29:06] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:29:07] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:29:07] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:29:07] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:29:07] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:29:07] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:29:07] xl.utils.env INFO: Using a generated random seed 7734491
[07/05 21:29:09] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:29:10] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:29:11] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:29:11] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:29:11] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:29:11] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:29:11] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:29:18] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:29:18] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:31:07] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 38, in run_step
    rewards = rewards - bs_rewards
TypeError: unsupported operand type(s) for -: 'dict' and 'dict'
[07/05 21:31:09] xl.engine.hooks INFO: Total training time: 0:01:51 (0:00:00 on hooks)
[07/05 21:31:09] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 285M
[07/05 21:33:54] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:33:55] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:33:55] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:33:55] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:33:55] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:33:55] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:33:55] xl.utils.env INFO: Using a generated random seed 55513866
[07/05 21:33:57] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:33:57] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:33:59] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:33:59] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:33:59] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:33:59] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:33:59] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:34:06] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:34:06] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:46:37] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:46:39] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:46:39] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:46:39] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:46:39] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:46:39] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:46:39] xl.utils.env INFO: Using a generated random seed 39317312
[07/05 21:46:41] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:46:41] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:46:43] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:46:43] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:46:43] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:46:43] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:46:43] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:47:18] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 21:47:20] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 21:47:20] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 21:47:20] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 21:47:20] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 21:47:20] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 21:47:20] xl.utils.env INFO: Using a generated random seed 20487027
[07/05 21:47:22] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 21:47:22] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 21:47:24] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 21:47:24] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:47:24] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:47:24] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 21:47:24] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 21:47:31] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 21:47:31] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 21:58:21] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 45, in run_step
    loss_dict = loss(outputs_dict)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/losses/reward_criterion.py", line 24, in forward
    rewards = rewards.view(-1, 1).expand_as(logP)
ValueError: Type must be a sub-type of ndarray type
[07/05 21:58:23] xl.engine.hooks INFO: Total training time: 0:10:52 (0:00:00 on hooks)
[07/05 21:58:23] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 285M
[07/05 22:11:11] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 22:14:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 22:14:06] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 22:14:06] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 22:14:06] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 22:14:06] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 22:14:06] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 22:14:06] xl.utils.env INFO: Using a generated random seed 6186071
[07/05 22:14:08] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 22:14:08] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 22:14:09] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 22:14:10] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:14:10] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:14:10] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:14:10] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:14:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 22:14:17] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 22:17:55] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 22:17:57] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 22:17:57] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 22:17:57] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 22:17:57] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 22:17:57] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 22:17:57] xl.utils.env INFO: Using a generated random seed 57406914
[07/05 22:17:59] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 22:17:59] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 22:18:01] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 22:18:01] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:18:01] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:18:01] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:18:01] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:18:08] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 22:18:08] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 22:18:22] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/rl_trainer.py", line 54, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 379, in _write_metrics
    metrics_dict = {k: v.detach().cpu().item() for k, v in loss_dict.items()}
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 379, in <dictcomp>
    metrics_dict = {k: v.detach().cpu().item() for k, v in loss_dict.items()}
AttributeError: 'numpy.float64' object has no attribute 'detach'
[07/05 22:22:22] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 22:22:24] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 22:22:24] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 22:22:24] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 22:22:24] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 22:22:24] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 22:22:24] xl.utils.env INFO: Using a generated random seed 24138000
[07/05 22:22:26] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 22:22:26] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 22:22:27] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 22:22:27] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:22:27] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:22:27] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:22:27] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:22:34] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 22:22:34] xl.engine.train_loop INFO: Starting training from iteration 0
[07/05 22:23:45] xmodaler INFO: Rank of current process: 0. World size: 1
[07/05 22:23:46] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/05 22:23:46] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/05 22:23:46] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
    ATT_EMBED_DROPOUT: 0.1

[07/05 22:23:46] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/mscoco_open_source
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: RLTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: /export1/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 1600
  DECODER: UpDownDecoder
  DECODER_DIM: 1000
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1000
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1000
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.1
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.1
    DROPOUT2: 0.1
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1000
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/05 22:23:46] xmodaler INFO: Full config saved to ./output/config.yaml
[07/05 22:23:46] xl.utils.env INFO: Using a generated random seed 46884824
[07/05 22:23:48] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1000)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1000, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3000, 1000)
    (dropout1): Dropout(p=0.1, inplace=False)
    (lstm2): LSTMCell(2000, 1000)
    (dropout2): Dropout(p=0.1, inplace=False)
    (att): BaseAttention(
      (w_h): Linear(in_features=1000, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1000, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1000, out_features=10200, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/05 22:23:49] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/05 22:23:50] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/05 22:23:50] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:23:50] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:23:50] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/05 22:23:50] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/05 22:23:57] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/05 22:23:57] xl.engine.train_loop INFO: Starting training from iteration 0
