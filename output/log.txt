[07/07 15:42:16] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:42:17] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:42:17] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:42:17] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  #FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  #ANNO_FOLDER:  '/export1/dataset/open_source/mscoco'
  FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  #VOCAB: '/export1/dataset/open_source/mscoco/coco_vocabulary.txt'
  VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  #VAL_ANNFILE: '/export1/dataset/open_source/mscoco/captions_val5k.json'
  #TEST_ANNFILE: '/export1/dataset/open_source/mscoco/captions_test5k.json'
  VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:42:17] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: D:/export/dataset/mscoco_open_source
  FEATS_FOLDER: D:/export/dataset/mscoco_open_source/features/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: D:/export/dataset/mscoco_open_source/captions_test5k.json
  VAL_ANNFILE: D:/export/dataset/mscoco_open_source/captions_val5k.json
  VOCAB: D:/export/dataset/mscoco_open_source/coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:42:17] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:42:17] xl.utils.env INFO: Using a generated random seed 17718925
[07/07 15:44:05] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:44:07] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:44:07] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:44:07] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:44:07] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:44:07] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:44:07] xl.utils.env INFO: Using a generated random seed 7444915
[07/07 15:45:43] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:45:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:45:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:45:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:45:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:45:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:45:45] xl.utils.env INFO: Using a generated random seed 45197980
[07/07 15:45:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 15:45:48] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 15:45:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 15:45:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:45:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:45:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:45:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:45:53] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 15:45:53] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 15:55:00] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 15:55:01] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 15:55:01] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 15:55:01] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 15:55:01] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 15:55:01] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 15:55:01] xl.utils.env INFO: Using a generated random seed 1496450
[07/07 15:55:03] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 15:55:03] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 15:55:05] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 15:55:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:55:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:55:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 15:55:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 15:55:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 15:55:07] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:25:36] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:25:37] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:25:37] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:25:37] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:25:37] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:25:37] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:25:37] xl.utils.env INFO: Using a generated random seed 37995181
[07/07 16:25:39] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:25:40] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:25:41] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:25:41] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:25:41] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:25:41] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:25:41] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:25:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:25:44] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:27:20] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:27:21] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:27:21] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:27:21] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:27:21] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:27:21] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:27:21] xl.utils.env INFO: Using a generated random seed 21732096
[07/07 16:27:23] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:27:23] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:27:25] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:27:25] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:27:25] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:27:25] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:27:25] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:27:27] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:27:27] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:28:09] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:28:10] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:28:10] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:28:10] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:28:10] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:28:10] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:28:10] xl.utils.env INFO: Using a generated random seed 11028974
[07/07 16:28:12] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:28:13] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:28:14] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:28:14] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:28:14] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:28:14] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:28:14] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:28:16] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:28:16] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:29:16] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:29:17] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:29:17] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:29:17] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:29:17] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:29:17] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:29:17] xl.utils.env INFO: Using a generated random seed 18060370
[07/07 16:29:19] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:29:20] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:29:21] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:29:21] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:29:21] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:29:21] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:29:21] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:29:23] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:29:23] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:30:00] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:30:01] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:30:01] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:30:01] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:30:01] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:30:01] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:30:01] xl.utils.env INFO: Using a generated random seed 1451853
[07/07 16:30:03] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:30:03] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:30:05] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:30:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:30:05] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:05] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:30:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:30:07] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:30:53] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:30:54] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:30:54] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:30:54] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:30:54] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:30:54] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:30:54] xl.utils.env INFO: Using a generated random seed 54469016
[07/07 16:30:56] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:30:56] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:30:57] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:30:57] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:57] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:30:58] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:30:58] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:31:00] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:31:00] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:33:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:33:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:33:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:33:27] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:33:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:33:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:33:27] xl.utils.env INFO: Using a generated random seed 27902023
[07/07 16:33:29] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:33:30] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:33:31] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:33:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:33:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:33:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:33:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:33:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:33:33] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:36:32] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:36:33] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:36:33] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:36:33] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:36:33] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:36:33] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:36:33] xl.utils.env INFO: Using a generated random seed 33659654
[07/07 16:36:35] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:36:36] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:36:38] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:36:38] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:36:38] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:36:38] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:36:38] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:36:40] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:36:40] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:43:50] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:43:51] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:43:51] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:43:51] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:43:51] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:43:51] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:43:51] xl.utils.env INFO: Using a generated random seed 51589570
[07/07 16:43:53] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:43:53] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:43:55] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:43:55] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:43:55] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:43:55] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:43:55] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:43:57] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:43:57] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:46:39] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 60, in forward
    g_tfeats = layer_module(g_tfeats, vfeats, ext_g_tmasks, ext_vmasks, history_states_i)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 403, in forward
    x, _ = self.self_attn(lang_feats, lang_attention_mask, t_history_states)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 142, in forward
    self_output, attention_probs = self.self(input_tensor, attention_mask, history_states)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 73, in forward
    attention_scores = attention_scores + attention_mask
RuntimeError: The size of tensor a (96) must match the size of tensor b (32) at non-singleton dimension 0
[07/07 16:46:39] xl.engine.hooks INFO: Total training time: 0:02:41 (0:02:41 on hooks)
[07/07 16:46:39] xl.utils.events INFO:  iter: 0  total_loss: 9.573  data_time: 0.0229  lr: 0.0005  max_mem: 392M
[07/07 16:47:01] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:47:02] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:47:02] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:47:02] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:47:02] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:47:02] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:47:02] xl.utils.env INFO: Using a generated random seed 2783598
[07/07 16:47:04] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:47:05] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:47:06] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:47:06] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:47:06] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:47:06] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:47:06] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:47:08] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:47:08] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 16:51:19] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 16:51:20] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 16:51:20] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 16:51:20] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 16:51:20] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 16:51:20] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 16:51:20] xl.utils.env INFO: Using a generated random seed 20566708
[07/07 16:51:22] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 16:51:22] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 16:51:24] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 16:51:24] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:51:24] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:51:24] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 16:51:24] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 16:51:26] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 16:51:26] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:42:44] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:42:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:42:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:42:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:42:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:42:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:42:45] xl.utils.env INFO: Using a generated random seed 45872878
[07/07 17:42:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:42:48] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:42:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:42:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:42:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:42:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:42:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:42:51] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:42:51] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:42:57] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/transformer_enc_dec.py", line 107, in _forward
    decoder_out = self.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 60, in forward
    history_states = [None] * self.g_layers
TypeError: can't multiply sequence by non-int of type 'ModuleList'
[07/07 17:42:57] xl.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[07/07 17:42:57] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 177M
[07/07 17:44:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:44:49] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:44:49] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:44:49] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:44:49] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:44:49] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:44:49] xl.utils.env INFO: Using a generated random seed 49541614
[07/07 17:44:51] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:44:51] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:44:53] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:44:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:44:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:44:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:44:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:44:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:44:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:44:55] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/transformer_enc_dec.py", line 107, in _forward
    decoder_out = self.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 64, in forward
    history_states[i] = torch.cat([history_states[i], g_tfeats], dim=1)
TypeError: expected Tensor as element 0 in argument 0, but got NoneType
[07/07 17:44:55] xl.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[07/07 17:44:55] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 177M
[07/07 17:45:14] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:45:15] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:45:15] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:45:15] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:45:15] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:45:15] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:45:15] xl.utils.env INFO: Using a generated random seed 15904307
[07/07 17:45:17] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:45:18] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:45:19] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:45:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:45:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:45:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:45:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:45:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:45:21] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:46:41] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 64, in forward
    history_states[i] = torch.cat([history_states[i], g_tfeats], dim=1)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
[07/07 17:46:41] xl.engine.hooks INFO: Total training time: 0:01:19 (0:01:19 on hooks)
[07/07 17:46:41] xl.utils.events INFO:  iter: 0  total_loss: 9.579  data_time: 0.0211  lr: 0.0005  max_mem: 392M
[07/07 17:49:43] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:49:45] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:49:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:49:45] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:49:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:49:45] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:49:45] xl.utils.env INFO: Using a generated random seed 45313252
[07/07 17:49:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:49:47] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:49:48] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:49:48] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:49:48] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:49:48] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:49:48] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:49:50] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:49:50] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:50:39] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:50:40] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:50:40] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:50:40] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:50:40] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:50:40] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:50:40] xl.utils.env INFO: Using a generated random seed 40860894
[07/07 17:50:42] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:50:43] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:50:44] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:50:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:50:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:50:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:50:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:50:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:50:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:50:59] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:51:00] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:51:00] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:51:00] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:51:00] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:51:00] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:51:00] xl.utils.env INFO: Using a generated random seed 952328
[07/07 17:51:02] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:51:03] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:51:04] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:51:04] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:51:04] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:51:04] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:51:04] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:51:06] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:51:06] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:51:12] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 56, in forward
    shape[1] = 0
TypeError: 'torch.Size' object does not support item assignment
[07/07 17:51:12] xl.engine.hooks INFO: Total training time: 0:00:05 (0:00:05 on hooks)
[07/07 17:51:12] xl.utils.events INFO:  iter: 0  total_loss: 9.629  data_time: 0.0220  lr: 0.0005  max_mem: 392M
[07/07 17:54:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:54:05] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:54:05] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:54:05] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:54:05] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:54:05] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:54:05] xl.utils.env INFO: Using a generated random seed 5491337
[07/07 17:54:07] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:54:07] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:54:09] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:54:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:54:11] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:54:16] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 56, in forward
    shape[1] = 0
TypeError: 'torch.Size' object does not support item assignment
[07/07 17:54:16] xl.engine.hooks INFO: Total training time: 0:00:04 (0:00:04 on hooks)
[07/07 17:54:16] xl.utils.events INFO:  iter: 0  total_loss: 9.656  data_time: 0.0230  lr: 0.0005  max_mem: 392M
[07/07 17:54:25] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:54:26] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:54:26] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:54:26] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:54:26] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:54:26] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:54:26] xl.utils.env INFO: Using a generated random seed 26703062
[07/07 17:54:28] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:54:28] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:54:30] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:54:30] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:30] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:30] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:54:30] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:54:32] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:54:32] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:55:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:55:48] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:55:48] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:55:48] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:55:48] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:55:48] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:55:48] xl.utils.env INFO: Using a generated random seed 48756976
[07/07 17:55:50] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:55:50] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:55:52] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:55:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:55:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:55:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:55:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:55:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:55:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:58:02] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 58, in forward
    history_states = [g_tfeats.new(torch.as_tensor(shape))] * self.num_generation_layers
TypeError: expected TensorOptions(dtype=float, device=cuda, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=long int, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))
[07/07 17:58:02] xl.engine.hooks INFO: Total training time: 0:02:07 (0:02:07 on hooks)
[07/07 17:58:02] xl.utils.events INFO:  iter: 0  total_loss: 9.643  data_time: 0.0272  lr: 0.0005  max_mem: 392M
[07/07 17:58:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:58:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:58:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:58:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:58:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:58:41] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:58:41] xl.utils.env INFO: Using a generated random seed 41308281
[07/07 17:58:43] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:58:43] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:58:44] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:58:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:58:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:58:44] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:58:44] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:58:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:58:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 17:59:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 17:59:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 17:59:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 17:59:27] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 17:59:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 17:59:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 17:59:27] xl.utils.env INFO: Using a generated random seed 27499603
[07/07 17:59:29] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 17:59:29] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 17:59:31] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 17:59:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:59:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:59:31] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 17:59:31] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 17:59:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 17:59:33] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 18:02:43] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/transformer_decoder.py", line 64, in forward
    history_states[i] = torch.cat([history_states[i], g_tfeats], dim=1)
RuntimeError: Sizes of tensors must match except in dimension 0. Got 96 and 32 (The offending index is 0)
[07/07 18:02:43] xl.engine.hooks INFO: Total training time: 0:03:09 (0:03:09 on hooks)
[07/07 18:02:43] xl.utils.events INFO:  iter: 0  total_loss: 9.449  data_time: 0.0278  lr: 0.0005  max_mem: 392M
[07/07 18:13:41] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 18:13:42] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 18:13:42] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 18:13:42] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '/export1/dataset/mscoco_torch/feature/up_down_100'
  ANNO_FOLDER:  '/export1/dataset/open_source/mscoco_dataset'
  #FEATS_FOLDER: 'D:/export/dataset/mscoco_open_source/features/up_down_100'
  #ANNO_FOLDER:  'D:/export/dataset/mscoco_open_source'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 17

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: False
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 2
    NUM_GENERATION_LAYERS: 2
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['CrossEntropy']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '/export1/dataset/mscoco_open_source/mscoco_train_gts.pkl'
  CIDER_CACHED: '/export1/dataset/mscoco_open_source/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '/export1/dataset/open_source/mscoco_dataset/vocabulary.txt'
  #VOCAB: 'D:/export/dataset/mscoco_open_source/coco_vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '/export1/dataset/open_source/mscoco_dataset/captions_test5k.json'
  #VAL_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_val5k.json'
  #TEST_ANNFILE: 'D:/export/dataset/mscoco_open_source/captions_test5k.json'


[07/07 18:13:42] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: /export1/dataset/open_source/mscoco_dataset
  FEATS_FOLDER: /export1/dataset/mscoco_torch/feature/up_down_100
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: /export1/dataset/open_source/mscoco_dataset/captions_val5k.json
  VOCAB: /export1/dataset/open_source/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 17
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 512
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: /export1/dataset/mscoco_open_source/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: /export1/dataset/mscoco_open_source/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 18:13:42] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 18:13:42] xl.utils.env INFO: Using a generated random seed 42333456
[07/07 18:13:44] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 18:13:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 18:13:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 18:13:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 18:13:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 18:13:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 18:13:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 18:13:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 18:13:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:03:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:03:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:03:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:03:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:03:42] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:03:42] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:03:42] xl.utils.env INFO: Using a generated random seed 42065574
[07/07 19:03:43] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:03:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:03:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:03:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:03:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:03:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:03:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:03:47] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:03:47] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:08:50] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:08:52] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:08:52] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:08:52] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:08:52] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:08:52] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:08:52] xl.utils.env INFO: Using a generated random seed 52618761
[07/07 19:08:55] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:08:55] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:08:57] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:08:57] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:08:57] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:08:57] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:08:57] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:08:59] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:08:59] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:09:48] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:09:49] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:09:49] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:09:49] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:09:49] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:09:49] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:09:49] xl.utils.env INFO: Using a generated random seed 49780000
[07/07 19:09:51] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:09:51] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:09:53] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:09:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:09:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:09:53] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:09:53] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:09:55] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:09:55] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:10:14] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:10:15] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:10:15] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:10:15] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:10:15] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:10:15] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:10:15] xl.utils.env INFO: Using a generated random seed 15811702
[07/07 19:10:17] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:10:17] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:10:19] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:10:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:10:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:10:19] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:10:19] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:10:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:10:21] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:13:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:13:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:13:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:13:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:13:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:13:41] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:13:41] xl.utils.env INFO: Using a generated random seed 41775957
[07/07 19:13:44] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:13:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:13:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:13:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:13:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:13:46] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:13:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:13:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:13:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:18:18] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:18:19] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:18:19] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:18:19] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:18:19] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:18:19] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:18:19] xl.utils.env INFO: Using a generated random seed 19767747
[07/07 19:18:21] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:18:21] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:18:23] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:18:23] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:18:23] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:18:23] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:18:23] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:18:25] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:18:25] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 19:19:56] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 19:19:57] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 19:19:57] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 19:19:57] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 19:19:57] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 19:19:57] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 19:19:57] xl.utils.env INFO: Using a generated random seed 57552343
[07/07 19:19:59] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 19:19:59] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 19:20:01] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 19:20:01] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:20:01] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:20:01] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 19:20:01] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 19:20:03] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 19:20:03] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 21:01:21] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 21:01:22] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 21:01:22] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 21:01:22] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 21:01:22] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 21:01:22] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 21:01:22] xl.utils.env INFO: Using a generated random seed 22510294
[07/07 21:01:24] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 21:01:24] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 21:01:26] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 21:01:26] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:01:26] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:01:26] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:01:26] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:01:28] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 21:01:28] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 21:05:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 21:05:42] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 21:05:42] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 21:05:42] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 21:05:42] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 21:05:42] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 21:05:42] xl.utils.env INFO: Using a generated random seed 42116839
[07/07 21:05:44] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 21:05:44] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 21:05:45] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 21:05:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:05:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:05:45] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 21:05:45] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 21:05:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 21:05:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:21:20] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/updown_decoder.py", line 86, in forward
    input1 = torch.cat([h2_tm1, global_feats, wt], 1)
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
[07/07 22:21:25] xl.engine.hooks INFO: Total training time: 0:00:06 (0:00:06 on hooks)
[07/07 22:21:25] xl.utils.events INFO:  iter: 0  total_loss: 7.981  data_time: 0.0220  lr: 0.0005  max_mem: 936M
[07/07 22:22:07] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:22:09] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:22:09] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:22:09] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 22:22:09] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:22:09] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:22:09] xl.utils.env INFO: Using a generated random seed 9095487
[07/07 22:22:11] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:22:11] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 22:22:12] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 22:22:12] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:22:12] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:22:12] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:22:12] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:22:14] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:22:14] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:23:01] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 432, in test
    res = model(data, use_beam_search=True, output_sents=True)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 76, in forward
    return self.decode_beam_search(batched_inputs, output_sents)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 161, in decode_beam_search
    model=weakref.proxy(self)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/decode_strategy.py", line 35, in forward
    ret = self._forward(batched_inputs, model)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decode_strategy/beam_searcher.py", line 61, in _forward
    decoder_out = model.decoder(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/updown_decoder.py", line 86, in forward
    input1 = torch.cat([h2_tm1, global_feats, wt], 1)
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
[07/07 22:23:01] xl.engine.hooks INFO: Total training time: 0:00:29 (0:00:29 on hooks)
[07/07 22:23:01] xl.utils.events INFO:  iter: 0  total_loss: 8.003  data_time: 0.0215  lr: 0.0005  max_mem: 936M
[07/07 22:23:45] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:23:46] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:23:46] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:23:46] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 22:23:46] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:23:46] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:23:46] xl.utils.env INFO: Using a generated random seed 46513386
[07/07 22:23:48] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:23:48] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 22:23:50] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 22:23:50] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:23:50] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:23:50] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:23:50] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:23:52] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:23:52] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:24:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:24:48] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:24:48] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:24:48] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 22:24:48] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:24:48] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:24:48] xl.utils.env INFO: Using a generated random seed 48519501
[07/07 22:24:50] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:24:50] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 22:24:52] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 22:24:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:24:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:24:52] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 22:24:52] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 22:24:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:24:54] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 22:54:12] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:54:14] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:54:14] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/salstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:54:14] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/salstm.yaml:
_BASE_: "base_caption.yaml"

MODEL: 
  ENCODER: 'Encoder'
  SALSTM:
    ATT_EMBED_SIZE: 512
    ATT_EMBED_DROPOUT: 0.0
  


[07/07 22:54:14] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: SALSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  SALSTM:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:54:14] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:54:14] xl.utils.env INFO: Using a generated random seed 14270082
[07/07 22:54:58] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 22:55:00] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 22:55:00] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/salstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 22:55:00] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/salstm.yaml:
_BASE_: "base_caption.yaml"

MODEL: 
  ENCODER: 'Encoder'
  SALSTM:
    ATT_EMBED_SIZE: 512
    ATT_EMBED_DROPOUT: 0.0
  


[07/07 22:55:00] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: SALSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  SALSTM:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 22:55:00] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 22:55:00] xl.utils.env INFO: Using a generated random seed 219328
[07/07 22:56:26] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): SALSTMDecoder(
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
    (lstm): LSTMCell(2048, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 22:56:27] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 22:56:28] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 22:56:28] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 22:56:28] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 22:56:28] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 22:56:28] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 22:56:31] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 22:56:32] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:02:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:02:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:02:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:02:27] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 23:02:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:02:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:02:27] xl.utils.env INFO: Using a generated random seed 27878500
[07/07 23:02:31] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:02:31] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:02:33] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:02:33] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:02:33] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:02:33] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:02:33] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:02:35] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:02:35] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:05:39] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:05:40] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:05:40] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:05:40] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:05:40] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:05:40] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:05:40] xl.utils.env INFO: Using a generated random seed 40636974
[07/07 23:05:45] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:05:45] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:05:46] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:05:46] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:05:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:05:46] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:05:46] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:05:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:05:48] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:12:30] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:12:32] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:12:32] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:12:32] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:12:32] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:12:32] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:12:32] xl.utils.env INFO: Using a generated random seed 32361198
[07/07 23:14:47] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:14:47] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:14:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:14:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:14:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:14:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:14:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:16:02] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:16:06] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:20:03] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:20:04] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:20:04] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:20:04] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:20:04] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:20:04] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:20:04] xl.utils.env INFO: Using a generated random seed 4855251
[07/07 23:20:07] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:20:07] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:20:09] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:20:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:20:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:20:09] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:20:09] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:20:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:20:19] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:20:34] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:20:36] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:20:36] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:20:36] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:20:36] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:20:36] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:20:36] xl.utils.env INFO: Using a generated random seed 36223141
[07/07 23:22:40] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:22:41] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:22:42] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:22:42] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:22:42] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:22:42] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:22:42] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:22:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:22:44] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:23:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:23:05] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:23:05] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/transformer.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:23:05] xmodaler INFO: Contents of args.config_file=./configs/image_caption/transformer.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'MSCoCoDataset'
  VAL: 'MSCoCoDataset'
  TEST: 'MSCoCoDataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/mscoco_dataset/features/up_down'
  ANNO_FOLDER:  '../open_source_dataset/mscoco_dataset'
  SEQ_PER_SAMPLE:  5
  MAX_FEAT_NUM: 50

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 10200 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TransformerEncoder'
  ENCODER_DIM: 512
  DECODER: 'TransformerDecoder'
  DECODER_DIM: 512
  PREDICTOR: 'BasePredictor'
  PRED_DROPOUT: 0.5
  MAX_SEQ_LEN: 20

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 512
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'SinusoidEncoding'

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 512
    ACTIVATION: 'relu'
    USE_NORM: True
    DROPOUT: 0.5
    
####################################### BERT ############################################
  BERT:
    HIDDEN_SIZE: 512
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "relu"
    NUM_ATTENTION_HEADS: 8
    INTERMEDIATE_SIZE: 2048
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    NUM_HIDDEN_LAYERS: 3
    NUM_GENERATION_LAYERS: 3
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 30
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.9
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.8

####################################### losses ####################################### 
LOSSES:
  NAMES: ['LabelSmoothing']
  LABELSMOOTHING: 0.1

####################################### scorer ####################################### 
SCORER:
  NAME: 'BaseScorer'
  TYPES: ['Cider']
  WEIGHTS: [1.0]
  GT_PATH: '../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl'
  CIDER_CACHED: '../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl'
  EOS_ID: 0

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 1

####################################### evaluation ####################################### 
INFERENCE:
  NAME: 'COCOEvaler'
  VOCAB: '../open_source_dataset/mscoco_dataset/vocabulary.txt'
  ID_KEY: 'image_id'
  CAP_KEY: 'caption'
  VAL_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_val5k.json'
  TEST_ANNFILE: '../open_source_dataset/mscoco_dataset/captions_test5k.json'


[07/07 23:23:05] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: relu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 3
    NUM_HIDDEN_LAYERS: 3
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: TransformerDecoder
  DECODER_DIM: 512
  DEVICE: cuda
  ENCODER: TransformerEncoder
  ENCODER_DIM: 512
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 512
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: SinusoidEncoding
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 512
    USE_NORM: True
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:23:05] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:23:05] xl.utils.env INFO: Using a generated random seed 5714030
[07/07 23:23:09] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 512)
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): SinusoidEncoding()
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=512, bias=True)
    (embeddings_act): ReLU()
    (embeddings_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): TransformerDecoder(
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (2): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=512, out_features=512, bias=True)
            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=2048, out_features=512, bias=True)
          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=512, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:23:09] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:23:10] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:23:10] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:23:10] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:23:10] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:23:10] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:23:13] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:23:13] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:24:20] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:24:21] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:24:21] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:24:21] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 23:24:21] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:24:21] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:24:21] xl.utils.env INFO: Using a generated random seed 21690657
[07/07 23:24:25] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:24:25] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:24:27] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:24:27] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:27] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:27] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:27] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:29] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:24:29] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:24:40] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:24:41] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:24:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/image_caption/updown.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:24:41] xmodaler INFO: Contents of args.config_file=./configs/image_caption/updown.yaml:
_BASE_: "base_att_image_caption.yaml"

MODEL:
  UPDOWN:
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
    ATT_EMBED_DROPOUT: 0.0

[07/07 23:24:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/mscoco_dataset
  FEATS_FOLDER: ../open_source_dataset/mscoco_dataset/features/up_down
  MAX_FEAT_NUM: 50
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 5
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSCoCoDataset
  TRAIN: MSCoCoDataset
  VAL: MSCoCoDataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_test5k.json
  VAL_ANNFILE: ../open_source_dataset/mscoco_dataset/captions_val5k.json
  VOCAB: ../open_source_dataset/mscoco_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['LabelSmoothing']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: UpDownDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 20
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  UPDOWN:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
    DROPOUT1: 0.0
    DROPOUT2: 0.0
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 10200
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: ../open_source_dataset/mscoco_dataset/mscoco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: ../open_source_dataset/mscoco_dataset/mscoco_train_gts.pkl
  NAME: BaseScorer
  TYPES: ['Cider']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 30
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:24:41] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:24:41] xl.utils.env INFO: Using a generated random seed 41938792
[07/07 23:24:46] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(10200, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): UpDownDecoder(
    (lstm1): LSTMCell(3072, 1024)
    (lstm2): LSTMCell(2048, 1024)
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=10200, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:24:47] xl.datasets.common INFO: Serializing 113287 elements to byte tensors and concatenating them all ...
[07/07 23:24:49] xl.datasets.common INFO: Serialized dataset takes 115.74 MiB
[07/07 23:24:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:49] xl.datasets.common INFO: Serializing 5000 elements to byte tensors and concatenating them all ...
[07/07 23:24:49] xl.datasets.common INFO: Serialized dataset takes 0.17 MiB
[07/07 23:24:51] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:24:51] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:28:05] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:28:06] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:28:06] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/salstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:28:06] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/salstm.yaml:
_BASE_: "base_caption.yaml"

MODEL: 
  ENCODER: 'Encoder'
  SALSTM:
    ATT_EMBED_SIZE: 512
    ATT_EMBED_DROPOUT: 0.0
  


[07/07 23:28:06] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: SALSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  SALSTM:
    ATT_EMBED_DROPOUT: 0.0
    ATT_EMBED_SIZE: 512
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:28:06] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:28:06] xl.utils.env INFO: Using a generated random seed 6763652
[07/07 23:28:10] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): SALSTMDecoder(
    (att): BaseAttention(
      (w_h): Linear(in_features=1024, out_features=512, bias=False)
      (act): Tanh()
      (w_alpha): Linear(in_features=512, out_features=1, bias=False)
      (softmax): Softmax(dim=-1)
    )
    (p_att_feats): Linear(in_features=1024, out_features=512, bias=True)
    (lstm): LSTMCell(2048, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:28:11] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:28:11] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:28:11] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:28:11] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:28:11] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:28:11] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:28:13] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:28:13] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:28:37] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:28:38] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:28:38] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/mplstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:28:38] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/mplstm.yaml:
_BASE_: "base_caption.yaml"

MODEL:
  DECODER: 'MPLSTMDecoder'
  


[07/07 23:28:38] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: MPLSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:28:38] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:28:38] xl.utils.env INFO: Using a generated random seed 38995075
[07/07 23:28:42] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): MPLSTMDecoder(
    (lstm): LSTMCell(1024, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:28:43] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:28:44] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:28:44] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:28:44] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:28:44] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:28:44] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:28:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:28:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:28:47] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/rnn_att_enc_dec.py", line 40, in _forward
    inputs = self.decoder.preprocess(inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/mplstm_decoder.py", line 38, in preprocess
    gv_feat = batched_inputs[kfg.GLOBAL_FEATS]
KeyError: 'GLOBAL_FEATS'
[07/07 23:28:47] xl.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[07/07 23:28:47] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 88M
[07/07 23:30:21] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:30:22] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:30:22] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/mplstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:30:22] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/mplstm.yaml:
_BASE_: "base_caption.yaml"

MODEL:
  DECODER: 'MPLSTMDecoder'
  


[07/07 23:30:22] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: MPLSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: Encoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:30:22] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:30:22] xl.utils.env INFO: Using a generated random seed 22682734
[07/07 23:30:26] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder()
  (decoder): MPLSTMDecoder(
    (lstm): LSTMCell(1024, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:30:27] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:30:27] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:30:27] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:30:27] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:30:27] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:30:27] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:30:29] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:30:29] xl.engine.train_loop INFO: Starting training from iteration 0
[07/07 23:30:32] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 458, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/rnn_att_enc_dec.py", line 40, in _forward
    inputs = self.decoder.preprocess(inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/decoder/mplstm_decoder.py", line 38, in preprocess
    gv_feat = batched_inputs[kfg.GLOBAL_FEATS]
KeyError: 'GLOBAL_FEATS'
[07/07 23:30:32] xl.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[07/07 23:30:32] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 88M
[07/07 23:30:57] xmodaler INFO: Rank of current process: 0. World size: 1
[07/07 23:30:59] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/07 23:30:59] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/video_caption/msvd/mplstm.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/07 23:30:59] xmodaler INFO: Contents of args.config_file=./configs/video_caption/msvd/mplstm.yaml:
_BASE_: "base_caption.yaml"

MODEL:
  ENCODER: 'UpDownEncoder'
  DECODER: 'MPLSTMDecoder'
  


[07/07 23:30:59] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/msvd_dataset
  FEATS_FOLDER: ../open_source_dataset/msvd_dataset/features/resnet152
  MAX_FEAT_NUM: 25
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: MSVDDataset
  TRAIN: MSVDDataset
  VAL: MSVDDataset
DECODE_STRATEGY:
  BEAM_SIZE: 5
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: COCOEvaler
  TEST_ANNFILE: ../open_source_dataset/msvd_dataset/captions_test.json
  VAL_ANNFILE: ../open_source_dataset/msvd_dataset/captions_val.json
  VOCAB: ../open_source_dataset/msvd_dataset/vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['CrossEntropy']
LR_SCHEDULER:
  GAMMA: 0.8
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 512
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 2048
    NUM_ATTENTION_HEADS: 8
    NUM_GENERATION_LAYERS: 6
    NUM_HIDDEN_LAYERS: 12
    NUM_UNDERSTANDING_LAYERS: 6
    V_NUM_HIDDEN_LAYERS: 6
    V_TARGET_SIZE: 0
  DECODER: MPLSTMDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: UpDownEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 21
  META_ARCHITECTURE: RnnAttEncoderDecoder
  PREDICTOR: BasePredictor
  PRED_DROPOUT: 0.5
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 5492
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 50
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.9
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/07 23:30:59] xmodaler INFO: Full config saved to ./output/config.yaml
[07/07 23:30:59] xl.utils.env INFO: Using a generated random seed 59135708
[07/07 23:31:05] xl.engine.defaults INFO: Model:
RnnAttEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(5492, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): UpDownEncoder()
  (decoder): MPLSTMDecoder(
    (lstm): LSTMCell(1024, 1024)
  )
  (predictor): BasePredictor(
    (logits): Linear(in_features=1024, out_features=5492, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/07 23:31:06] xl.datasets.common INFO: Serializing 48748 elements to byte tensors and concatenating them all ...
[07/07 23:31:06] xl.datasets.common INFO: Serialized dataset takes 19.99 MiB
[07/07 23:31:06] xl.datasets.common INFO: Serializing 97 elements to byte tensors and concatenating them all ...
[07/07 23:31:06] xl.datasets.common INFO: Serialized dataset takes 0.69 MiB
[07/07 23:31:06] xl.datasets.common INFO: Serializing 670 elements to byte tensors and concatenating them all ...
[07/07 23:31:06] xl.datasets.common INFO: Serialized dataset takes 4.62 MiB
[07/07 23:31:08] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/07 23:31:08] xl.engine.train_loop INFO: Starting training from iteration 0
[07/08 00:24:01] xmodaler INFO: Rank of current process: 0. World size: 1
[07/08 00:24:03] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/08 00:24:03] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/pretrain/pretrain.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/08 00:24:03] xmodaler INFO: Contents of args.config_file=./configs/pretrain/pretrain.yaml:
####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'ConceptualCaptionsDataset'
  VAL: ''
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/ConceptualCaptions/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/ConceptualCaptions'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### Engine #########################################
ENGINE:
  NAME: 'DefaultTrainer'

######################################### Scheduled sampling #########################################
SCHEDULED_SAMPLING:
  START_EPOCH: 0
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25

######################################### MODEL #########################################
MODEL:
  VOCAB_SIZE: 30522 # include <BOS>/<EOS>
  META_ARCHITECTURE: 'TransformerEncoderDecoder'
  ENCODER: 'TwoStreamBertEncoder'
  DECODER: 'DecoupleBertDecoder'
  PREDICTOR: 'BertPredictionHead'
  V_PREDICTOR: 'BertVisualPredictionHead'
  MAX_SEQ_LEN: 36

######################################### BERT #########################################
  BERT:
    HIDDEN_SIZE: 768
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: "gelu"
    NUM_ATTENTION_HEADS: 12
    INTERMEDIATE_SIZE: 3072
    INTERMEDIATE_DROP: 0.1
    FFN_DROPOUT_PROB: 0.1
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    V_TARGET_SIZE: 1601
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

#################################### Token embedding ####################################
  TOKEN_EMBED:
    NAME: 'TokenBaseEmbedding'
    DIM: 768
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
    POSITION: 'NNEmbeddingEncoding'
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3

#################################### Visual embedding ####################################
  VISUAL_EMBED:
    NAME: 'VisualBaseEmbedding'
    IN_DIM: 2048
    OUT_DIM: 768
    LOCATION_SIZE: 5
    ACTIVATION: 'none'
    USE_NORM: True
    DROPOUT: 0.1
  
####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### decode strategy ####################################### 
DECODE_STRATEGY:
  NAME: 'BeamSearcher'
  BEAM_SIZE: 3

####################################### losses ####################################### 
LOSSES:
  NAMES: ['PretrainLosses']

INFERENCE:
  VOCAB: ''

[07/08 00:24:03] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/ConceptualCaptions
  FEATS_FOLDER: ../open_source_dataset/ConceptualCaptions/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: ConceptualCaptionsDataset
  VAL: 
DECODE_STRATEGY:
  BEAM_SIZE: 3
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  CAP_KEY: caption
  ID_KEY: image_id
  NAME: 
  TEST_ANNFILE: captions_test5k.json
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['PretrainLosses']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 1601
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 36
  META_ARCHITECTURE: TransformerEncoderDecoder
  PREDICTOR: BertPredictionHead
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: BertVisualPredictionHead
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/08 00:24:03] xmodaler INFO: Full config saved to ./output/config.yaml
[07/08 00:24:03] xl.utils.env INFO: Using a generated random seed 3150096
[07/08 00:25:51] xl.engine.defaults INFO: Model:
TransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): BertPredictionHead(
    (transform): BertPredictionHeadTransform(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    )
    (decoder): Linear(in_features=768, out_features=30522, bias=True)
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
  (v_predictor): BertVisualPredictionHead(
    (transform): BertPredictionHeadTransform(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    )
    (decoder): Linear(in_features=768, out_features=1601, bias=True)
  )
)
[07/08 00:25:51] xl.datasets.common INFO: Serializing 21 elements to byte tensors and concatenating them all ...
[07/08 00:25:51] xl.datasets.common INFO: Serialized dataset takes 0.00 MiB
[07/08 00:28:05] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/08 00:28:05] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 03:33:44] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 03:33:45] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 03:33:45] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 03:33:45] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 03:33:45] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: 
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 03:33:45] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 03:33:45] xl.utils.env INFO: Using a generated random seed 46035463
[07/09 03:54:35] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 03:54:36] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 03:54:36] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 03:54:36] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 03:54:36] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: 
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 03:54:36] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 03:54:36] xl.utils.env INFO: Using a generated random seed 36955008
[07/09 03:55:15] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 03:55:16] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 03:55:16] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 03:55:16] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 03:55:16] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: 
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: coco_vocabulary.txt
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 03:55:16] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 03:55:16] xl.utils.env INFO: Using a generated random seed 16859350
[07/09 03:57:04] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 03:57:06] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 03:57:06] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 03:57:06] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 03:57:06] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: 
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 03:57:06] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 03:57:06] xl.utils.env INFO: Using a generated random seed 6136679
[07/09 03:57:44] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 03:57:46] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 03:57:46] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 03:57:46] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 03:57:46] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: 
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 03:57:46] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 03:57:46] xl.utils.env INFO: Using a generated random seed 46439872
[07/09 03:58:34] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 03:58:36] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 03:58:36] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 03:58:36] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 03:58:36] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 03:58:36] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 03:58:36] xl.utils.env INFO: Using a generated random seed 36545259
[07/09 04:02:41] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:04:30] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 04:04:31] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 04:04:31] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 04:04:31] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 04:04:31] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 04:04:31] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 04:04:31] xl.utils.env INFO: Using a generated random seed 31936114
[07/09 04:04:35] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:15:24] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 04:15:26] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 04:15:26] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 04:15:26] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 04:15:26] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 04:15:26] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 04:15:26] xl.utils.env INFO: Using a generated random seed 26112896
[07/09 04:15:29] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:18:06] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 04:18:08] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 04:18:08] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 04:18:08] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 04:18:08] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 04:18:08] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 04:18:08] xl.utils.env INFO: Using a generated random seed 8245504
[07/09 04:18:12] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:21:39] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 04:21:41] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 04:21:41] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 04:21:41] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 04:21:41] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 04:21:41] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 04:21:41] xl.utils.env INFO: Using a generated random seed 41162375
[07/09 04:21:43] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:27:53] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 04:27:54] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 04:27:54] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 04:27:54] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 04:27:54] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 04:27:54] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 04:27:54] xl.utils.env INFO: Using a generated random seed 54443502
[07/09 04:27:55] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:33:31] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 04:33:33] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 04:33:33] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 04:33:33] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 04:33:33] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 04:33:33] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 04:33:33] xl.utils.env INFO: Using a generated random seed 33127610
[07/09 04:33:36] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 04:33:55] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 04:33:58] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 04:34:34] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 04:34:34] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 05:07:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 05:07:49] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 05:07:49] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 05:07:49] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 05:07:49] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 05:07:49] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 05:07:49] xl.utils.env INFO: Using a generated random seed 49167072
[07/09 05:07:52] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 05:08:00] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 05:08:04] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 05:08:04] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 05:08:04] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 05:08:05] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 05:08:06] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 05:08:28] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 05:08:30] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 05:08:30] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 05:08:30] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 05:08:30] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 05:08:30] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 05:08:30] xl.utils.env INFO: Using a generated random seed 30477249
[07/09 05:08:33] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 05:08:39] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 05:08:42] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 05:08:43] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 05:08:43] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 05:08:44] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 05:08:45] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 05:08:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 05:08:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 05:08:53] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "d:\export\opensource\xmodaler\xmodaler\engine\train_loop.py", line 147, in train
    self.run_step()
  File "d:\export\opensource\xmodaler\xmodaler\engine\defaults.py", line 453, in run_step
    data = next(self._train_data_loader_iter)
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 521, in __next__
    data = self._next_data()
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "d:\export\opensource\xmodaler\xmodaler\datasets\common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "d:\export\opensource\xmodaler\xmodaler\utils\serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "d:\export\opensource\xmodaler\xmodaler\datasets\images\vqa.py", line 163, in __call__
    features, image_locations = read_np_bbox(image_path, self.max_feat_num)
  File "d:\export\opensource\xmodaler\xmodaler\functional\func_io.py", line 27, in read_np_bbox
    content = read_np(path)
  File "d:\export\opensource\xmodaler\xmodaler\functional\func_io.py", line 17, in read_np
    content = np.load(path)
  File "C:\ProgramData\Anaconda3\lib\site-packages\numpy\lib\npyio.py", line 444, in load
    raise ValueError("Cannot load file containing pickled data "
ValueError: Cannot load file containing pickled data when allow_pickle=False
[07/09 05:08:53] xl.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
[07/09 05:08:53] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 242M
[07/09 05:09:20] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 05:09:21] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 05:09:21] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 05:09:21] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 05:09:21] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 05:09:21] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 05:09:21] xl.utils.env INFO: Using a generated random seed 21942498
[07/09 05:09:25] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 05:09:30] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 05:09:34] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 05:09:34] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 05:09:34] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 05:09:35] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 05:09:36] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 05:09:38] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 05:09:38] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 05:09:57] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "d:\export\opensource\xmodaler\xmodaler\engine\train_loop.py", line 147, in train
    self.run_step()
  File "d:\export\opensource\xmodaler\xmodaler\engine\defaults.py", line 453, in run_step
    data = next(self._train_data_loader_iter)
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 521, in __next__
    data = self._next_data()
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "d:\export\opensource\xmodaler\xmodaler\datasets\common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "d:\export\opensource\xmodaler\xmodaler\utils\serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "d:\export\opensource\xmodaler\xmodaler\datasets\images\vqa.py", line 163, in __call__
    features, image_locations = read_np_bbox(image_path, self.max_feat_num)
  File "d:\export\opensource\xmodaler\xmodaler\functional\func_io.py", line 27, in read_np_bbox
    content = read_np(path)
  File "d:\export\opensource\xmodaler\xmodaler\functional\func_io.py", line 17, in read_np
    content = np.load(path)
  File "C:\ProgramData\Anaconda3\lib\site-packages\numpy\lib\npyio.py", line 444, in load
    raise ValueError("Cannot load file containing pickled data "
ValueError: Cannot load file containing pickled data when allow_pickle=False
[07/09 05:09:57] xl.engine.hooks INFO: Total training time: 0:00:19 (0:00:00 on hooks)
[07/09 05:09:57] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 242M
[07/09 05:11:42] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 05:11:43] xmodaler INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.19.2
detectron2              0.3 @d:\export\net\imagenet\detectron2\detectron2
Compiler                MSVC 191627045
CUDA compiler           CUDA 11.1
detectron2 arch flags   d:\export\net\imagenet\detectron2\detectron2\_C.cp38-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @C:\ProgramData\Anaconda3\lib\site-packages\torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce RTX 2060 (arch=7.5)
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
Pillow                  8.0.1
torchvision             0.10.0 @C:\ProgramData\Anaconda3\lib\site-packages\torchvision
torchvision arch flags  C:\ProgramData\Anaconda3\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.3.post20210317
iopath                  0.1.8
cv2                     Not found
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 2019
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/09 05:11:43] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 05:11:43] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 05:11:43] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 05:11:44] xmodaler INFO: Full config saved to ./output\config.yaml
[07/09 05:11:44] xl.utils.env INFO: Using a generated random seed 44041265
[07/09 05:11:54] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 05:11:59] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 05:12:03] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 05:12:03] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 05:12:03] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 05:12:04] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 05:12:05] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 05:12:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 05:12:07] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 05:12:12] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\numpy\lib\npyio.py", line 447, in load
    return pickle.load(fid, **pickle_kwargs)
_pickle.UnpicklingError: invalid load key, '\xd0'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\export\opensource\xmodaler\xmodaler\engine\train_loop.py", line 147, in train
    self.run_step()
  File "d:\export\opensource\xmodaler\xmodaler\engine\defaults.py", line 453, in run_step
    data = next(self._train_data_loader_iter)
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 521, in __next__
    data = self._next_data()
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\ProgramData\Anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "d:\export\opensource\xmodaler\xmodaler\datasets\common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "d:\export\opensource\xmodaler\xmodaler\utils\serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "d:\export\opensource\xmodaler\xmodaler\datasets\images\vqa.py", line 163, in __call__
    features, image_locations = read_np_bbox(image_path, self.max_feat_num)
  File "d:\export\opensource\xmodaler\xmodaler\functional\func_io.py", line 27, in read_np_bbox
    content = read_np(path)
  File "d:\export\opensource\xmodaler\xmodaler\functional\func_io.py", line 17, in read_np
    content = np.load(path, allow_pickle=True)
  File "C:\ProgramData\Anaconda3\lib\site-packages\numpy\lib\npyio.py", line 449, in load
    raise IOError(
OSError: Failed to interpret file '../open_source_dataset/VQA/features/up_down\\565546.npz' as a pickle
[07/09 05:12:18] xl.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[07/09 05:12:18] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 242M
[07/09 14:39:29] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:39:30] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:39:30] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:39:30] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:39:30] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:39:30] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:39:30] xl.utils.env INFO: Using a generated random seed 30420397
[07/09 14:39:32] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:41:53] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:41:55] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:42:01] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:42:01] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:42:45] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:42:46] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:42:50] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:42:50] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 14:42:50] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 453, in run_step
    data = next(self._train_data_loader_iter)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/export1/open_source/xmodaler/xmodaler/datasets/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/export1/open_source/xmodaler/xmodaler/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/datasets/images/vqa.py", line 186, in __call__
    ret.update({ kfg.U_TARGET_IDS: target })
UnboundLocalError: local variable 'target' referenced before assignment
[07/09 14:42:50] xl.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[07/09 14:42:50] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 242M
[07/09 14:44:53] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:44:55] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:44:55] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:44:55] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:44:55] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:44:55] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:44:55] xl.utils.env INFO: Using a generated random seed 55181951
[07/09 14:44:57] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:45:00] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:45:03] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:45:04] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:45:04] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:45:04] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:45:06] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:45:08] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:45:08] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 14:47:02] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:47:03] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:47:03] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:47:03] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:47:03] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:47:03] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:47:03] xl.utils.env INFO: Using a generated random seed 3714220
[07/09 14:47:05] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:47:08] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:47:12] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:47:12] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:47:12] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:47:13] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:47:14] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:47:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:47:17] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 14:50:29] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:50:30] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:50:30] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:50:30] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:50:30] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:50:31] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:50:31] xl.utils.env INFO: Using a generated random seed 31043237
[07/09 14:50:32] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:50:36] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:50:39] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:50:39] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:50:39] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:50:40] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:50:41] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:50:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:50:44] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 14:52:24] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 461, in run_step
    outputs_dict = self.model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/transformer_enc_dec.py", line 96, in _forward
    encoder_out_v = self.encoder(inputs, mode='v')
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/encoder/two_stream_bert_encoder.py", line 54, in forward
    vfeats, _ = layer_module(vfeats, ext_vmasks)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 331, in forward
    attention_output, attention_probs = self.attention(hidden_states, attention_mask, history_states)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 143, in forward
    attention_output = self.output(self_output, input_tensor)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/layers/bert.py", line 119, in forward
    hidden_states = self.LayerNorm(hidden_states + input_tensor)
RuntimeError: The size of tensor a (768) must match the size of tensor b (1024) at non-singleton dimension 2
[07/09 14:52:24] xl.engine.hooks INFO: Total training time: 0:01:39 (0:00:00 on hooks)
[07/09 14:52:24] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 252M
[07/09 14:52:43] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:52:44] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:52:44] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:52:44] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:52:44] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:52:44] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:52:44] xl.utils.env INFO: Using a generated random seed 44501930
[07/09 14:52:46] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:52:49] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:52:53] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:52:53] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:52:53] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:52:54] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:52:55] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:52:58] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:52:58] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 14:53:34] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:53:35] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:53:35] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:53:35] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:53:35] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: relu
    DIM: 1024
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: none
    POSITION_MAX_LEN: 5000
    TYPE_VOCAB_SIZE: 0
    USE_NORM: False
  VISUAL_EMBED:
    ACTIVATION: relu
    DROPOUT: 0.5
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 0
    NAME: VisualBaseEmbedding
    OUT_DIM: 1024
    USE_NORM: False
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:53:36] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:53:36] xl.utils.env INFO: Using a generated random seed 36074423
[07/09 14:53:37] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 1024)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=1024, bias=True)
    (embeddings_act): ReLU()
    (embeddings_dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:53:41] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:53:44] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:53:44] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:53:44] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:53:45] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:53:46] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:53:49] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:53:49] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 14:57:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 14:57:48] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 14:57:48] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 14:57:48] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 14:57:48] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 14:57:48] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 14:57:48] xl.utils.env INFO: Using a generated random seed 49032013
[07/09 14:57:50] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 14:57:54] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 14:57:57] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 14:57:58] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 14:57:58] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 14:57:58] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 14:58:00] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 14:58:02] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 14:58:02] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 15:09:46] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 15:09:47] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 15:09:47] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 15:09:47] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 15:09:47] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 15:09:47] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 15:09:47] xl.utils.env INFO: Using a generated random seed 47993754
[07/09 15:09:49] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 15:09:53] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 15:09:57] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 15:09:57] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 15:09:57] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 15:09:58] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 15:10:00] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 15:10:04] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 15:10:04] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 15:10:04] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 147, in train
    self.run_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 453, in run_step
    data = next(self._train_data_loader_iter)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/export1/open_source/xmodaler/xmodaler/datasets/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/export1/open_source/xmodaler/xmodaler/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/datasets/images/vqa.py", line 185, in __call__
    ret.update({ kfg.U_TARGET_IDS: target.astype('float32') })
UnboundLocalError: local variable 'target' referenced before assignment
[07/09 15:10:04] xl.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[07/09 15:10:04] xl.utils.events INFO:  iter: 0    lr: N/A  max_mem: 211M
[07/09 15:16:19] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 15:16:21] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 15:16:21] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 15:16:21] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 15:16:21] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 15:16:21] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 15:16:21] xl.utils.env INFO: Using a generated random seed 21244183
[07/09 15:16:24] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 15:19:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 15:19:27] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 15:19:27] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 15:19:27] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 15:19:27] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 15:19:27] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 15:19:27] xl.utils.env INFO: Using a generated random seed 27878300
[07/09 15:19:29] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 15:19:33] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 15:19:36] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 15:19:37] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 15:19:37] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 15:19:38] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 15:19:39] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 15:19:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 15:19:44] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 15:24:52] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 15:24:54] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 15:24:54] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 15:24:54] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 15:24:54] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 15:24:54] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 15:24:54] xl.utils.env INFO: Using a generated random seed 54164933
[07/09 15:24:56] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 15:25:00] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 15:25:04] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 15:25:05] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 15:25:05] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 15:25:05] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 15:25:07] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 15:25:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 15:25:11] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 15:29:15] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 300, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model, self.test_data_loader, self.evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 428, in test
    for data in tqdm.tqdm(test_data_loader):
  File "/home/v-yehl/.local/lib/python3.6/site-packages/tqdm/std.py", line 1193, in __iter__
    for obj in iterable:
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/export1/open_source/xmodaler/xmodaler/datasets/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/export1/open_source/xmodaler/xmodaler/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/datasets/images/vqa.py", line 163, in __call__
    features, image_locations = read_np_bbox(image_path, self.max_feat_num)
  File "/export1/open_source/xmodaler/xmodaler/functional/func_io.py", line 27, in read_np_bbox
    content = read_np(path)
  File "/export1/open_source/xmodaler/xmodaler/functional/func_io.py", line 17, in read_np
    content = np.load(path)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/numpy/lib/npyio.py", line 416, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: '../open_source_dataset/VQA/features/up_down_test2015/565546.npz'
[07/09 15:29:28] xl.engine.hooks INFO: Total training time: 0:00:15 (0:00:15 on hooks)
[07/09 15:29:28] xl.utils.events INFO:  iter: 0  total_loss: 4554  data_time: 0.1128  lr: 0.0005  max_mem: 868M
[07/09 15:32:10] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 15:32:12] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 15:32:12] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 15:32:12] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 15:32:12] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 15:32:12] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 15:32:12] xl.utils.env INFO: Using a generated random seed 12341029
[07/09 15:32:14] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 15:32:17] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 15:32:20] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 15:32:21] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 15:32:21] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 15:32:22] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 15:32:23] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 15:32:28] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 15:32:28] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 15:54:36] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 15:54:37] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 15:54:37] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 15:54:37] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  GENERATION_MODE: False

[07/09 15:54:37] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: image_id
  NAME: VQAEvaler
  TEST_ANNFILE: captions_test5k.json
  VALUE: caption
  VAL_ANNFILE: captions_val5k.json
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 15:54:37] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 15:54:37] xl.utils.env INFO: Using a generated random seed 37989516
[07/09 15:54:39] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 15:54:43] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 15:54:46] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 15:54:47] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 15:54:47] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 15:54:48] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 15:54:49] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 15:54:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 15:54:54] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 16:27:21] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 16:27:23] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 16:27:23] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 16:27:23] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 16:27:23] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 16:27:23] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 16:27:23] xl.utils.env INFO: Using a generated random seed 23212700
[07/09 16:27:25] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 16:27:28] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 16:27:32] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 16:27:32] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 16:27:32] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 16:27:34] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 16:27:35] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:27:36] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:27:37] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:27:37] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:27:37] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:27:37] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:27:37] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:27:37] xl.utils.env INFO: Using a generated random seed 37677357
[07/09 17:27:39] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:27:42] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:27:46] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:27:46] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:27:46] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:27:47] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:27:49] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:27:56] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:27:56] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:28:24] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:28:26] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:28:26] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:28:26] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:28:26] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:28:26] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:28:26] xl.utils.env INFO: Using a generated random seed 26127299
[07/09 17:28:28] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:28:31] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:28:34] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:28:35] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:28:35] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:28:36] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:28:37] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:28:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:28:46] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:29:25] xl.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 148, in train
    self.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/train_loop.py", line 178, in after_step
    h.after_step()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 372, in after_step
    self._do_eval()
  File "/export1/open_source/xmodaler/xmodaler/engine/hooks.py", line 351, in _do_eval
    results = self._func()
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 313, in val_and_save_results
    self.test(self.cfg, self.model, self.val_data_loader, self.val_evaluator)
  File "/export1/open_source/xmodaler/xmodaler/engine/defaults.py", line 441, in test
    res = model(data)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/base_enc_dec.py", line 72, in forward
    return self._forward(batched_inputs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/meta_arch/transformer_enc_dec.py", line 109, in _forward
    tlogits = self.predictor(inputs)
  File "/home/v-yehl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/export1/open_source/xmodaler/xmodaler/modeling/predictor/multimodal_predictor.py", line 109, in forward
    probs = torch.max(probs)[1].data
IndexError: index 1 is out of bounds for dimension 0 with size 0
[07/09 17:29:25] xl.engine.hooks INFO: Total training time: 0:00:19 (0:00:19 on hooks)
[07/09 17:29:25] xl.utils.events INFO:  iter: 0  total_loss: 4608  data_time: 0.0644  lr: 0.0005  max_mem: 896M
[07/09 17:29:53] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:29:54] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:29:54] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:29:54] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:29:54] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:29:54] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:29:54] xl.utils.env INFO: Using a generated random seed 54805022
[07/09 17:29:56] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:30:00] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:30:03] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:30:03] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:30:04] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:30:04] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:30:06] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:30:12] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:30:12] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:33:14] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:33:15] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:33:15] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:33:15] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:33:15] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:33:15] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:33:15] xl.utils.env INFO: Using a generated random seed 15789550
[07/09 17:33:17] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:33:22] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:33:25] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:33:26] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:33:26] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:33:27] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:33:28] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:33:38] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:33:38] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:36:36] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:36:37] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:36:37] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:36:37] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:36:37] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:36:37] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:36:37] xl.utils.env INFO: Using a generated random seed 37711807
[07/09 17:36:39] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:36:43] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:36:46] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:36:47] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:36:47] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:36:48] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:36:49] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:36:53] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:36:53] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:37:54] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:37:55] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:37:55] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:37:55] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:37:55] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:37:55] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:37:55] xl.utils.env INFO: Using a generated random seed 55329508
[07/09 17:37:57] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:38:00] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:38:04] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:38:04] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:38:04] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:38:05] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:38:06] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:38:10] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:38:10] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:39:47] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:39:48] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:39:48] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:39:48] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:39:48] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: VQADataset
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:39:48] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:39:48] xl.utils.env INFO: Using a generated random seed 48916357
[07/09 17:39:50] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:39:54] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:39:58] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:39:58] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:39:58] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:39:59] xl.datasets.common INFO: Serializing 447793 elements to byte tensors and concatenating them all ...
[07/09 17:40:00] xl.datasets.common INFO: Serialized dataset takes 43.70 MiB
[07/09 17:40:03] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:40:03] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:41:03] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:41:04] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:41:04] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:41:04] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:41:04] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:41:04] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:41:04] xl.utils.env INFO: Using a generated random seed 4920062
[07/09 17:41:06] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:41:10] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:41:14] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:41:16] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:41:16] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:41:18] xl.utils.events INFO:  eta: 1 day, 3:50:43  iter: 19  total_loss: 405.9  time: 0.0716  data_time: 0.0249  lr: 0.0005  max_mem: 1030M
[07/09 17:41:20] xl.utils.events INFO:  eta: 1 day, 3:59:20  iter: 39  total_loss: 21  time: 0.0723  data_time: 0.0241  lr: 0.0005  max_mem: 1030M
[07/09 17:41:21] xl.utils.events INFO:  eta: 1 day, 3:57:36  iter: 59  total_loss: 16.65  time: 0.0716  data_time: 0.0216  lr: 0.0005  max_mem: 1030M
[07/09 17:41:23] xl.utils.events INFO:  eta: 1 day, 3:54:54  iter: 79  total_loss: 16.93  time: 0.0713  data_time: 0.0215  lr: 0.0005  max_mem: 1030M
[07/09 17:41:24] xl.utils.events INFO:  eta: 1 day, 3:54:53  iter: 99  total_loss: 15.32  time: 0.0712  data_time: 0.0218  lr: 0.0005  max_mem: 1030M
[07/09 17:41:26] xl.utils.events INFO:  eta: 1 day, 3:57:32  iter: 119  total_loss: 16.32  time: 0.0712  data_time: 0.0224  lr: 0.0005  max_mem: 1030M
[07/09 17:41:27] xl.utils.events INFO:  eta: 1 day, 3:58:22  iter: 139  total_loss: 16.3  time: 0.0713  data_time: 0.0225  lr: 0.0005  max_mem: 1030M
[07/09 17:41:29] xl.utils.events INFO:  eta: 1 day, 4:00:08  iter: 159  total_loss: 17.25  time: 0.0714  data_time: 0.0228  lr: 0.0005  max_mem: 1030M
[07/09 17:41:30] xl.utils.events INFO:  eta: 1 day, 4:01:20  iter: 179  total_loss: 15.95  time: 0.0716  data_time: 0.0238  lr: 0.0005  max_mem: 1030M
[07/09 17:41:32] xl.utils.events INFO:  eta: 1 day, 4:02:01  iter: 199  total_loss: 16.97  time: 0.0716  data_time: 0.0223  lr: 0.0005  max_mem: 1030M
[07/09 17:41:33] xl.utils.events INFO:  eta: 1 day, 4:06:12  iter: 219  total_loss: 17.17  time: 0.0717  data_time: 0.0221  lr: 0.0005  max_mem: 1031M
[07/09 17:41:35] xl.utils.events INFO:  eta: 1 day, 4:10:52  iter: 239  total_loss: 16.61  time: 0.0719  data_time: 0.0241  lr: 0.0005  max_mem: 1031M
[07/09 17:41:36] xl.utils.events INFO:  eta: 1 day, 4:13:32  iter: 259  total_loss: 16.44  time: 0.0718  data_time: 0.0221  lr: 0.0005  max_mem: 1031M
[07/09 17:41:38] xl.utils.events INFO:  eta: 1 day, 4:12:05  iter: 279  total_loss: 15.22  time: 0.0719  data_time: 0.0237  lr: 0.0005  max_mem: 1031M
[07/09 17:41:39] xl.utils.events INFO:  eta: 1 day, 4:13:09  iter: 299  total_loss: 15.78  time: 0.0719  data_time: 0.0226  lr: 0.0005  max_mem: 1033M
[07/09 17:41:41] xl.utils.events INFO:  eta: 1 day, 4:08:46  iter: 319  total_loss: 16.42  time: 0.0718  data_time: 0.0232  lr: 0.0005  max_mem: 1033M
[07/09 17:41:42] xl.utils.events INFO:  eta: 1 day, 4:08:53  iter: 339  total_loss: 16.51  time: 0.0719  data_time: 0.0231  lr: 0.0005  max_mem: 1033M
[07/09 17:41:43] xl.utils.events INFO:  eta: 1 day, 4:09:19  iter: 359  total_loss: 14.91  time: 0.0718  data_time: 0.0220  lr: 0.0005  max_mem: 1033M
[07/09 17:42:00] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:42:01] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:42:01] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:42:01] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:42:01] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:42:01] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:42:01] xl.utils.env INFO: Using a generated random seed 1380728
[07/09 17:42:03] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:42:06] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:42:10] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:42:31] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:42:32] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:42:32] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:42:32] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:42:32] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:42:32] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:42:32] xl.utils.env INFO: Using a generated random seed 32907333
[07/09 17:42:34] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:42:38] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:42:41] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:44:24] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:44:25] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:44:25] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:44:25] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:44:25] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:44:25] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:44:25] xl.utils.env INFO: Using a generated random seed 25523190
[07/09 17:44:27] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:44:30] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:44:34] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:44:44] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:44:44] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:44:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:44:54] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:49:11] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 17:49:12] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 17:49:12] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 17:49:12] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 17:49:12] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 17:49:12] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 17:49:12] xl.utils.env INFO: Using a generated random seed 12616912
[07/09 17:49:14] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 17:49:18] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 17:49:21] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 17:49:22] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 17:49:22] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 17:49:25] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 17:49:25] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 17:49:50] xl.engine.hooks INFO: {'accuracy': 0.0}
[07/09 18:05:26] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 18:05:28] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 18:05:28] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 18:05:28] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 18:05:28] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 18:05:28] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 18:05:28] xl.utils.env INFO: Using a generated random seed 28464562
[07/09 18:05:30] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 18:05:34] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 18:05:38] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 18:05:38] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 18:05:38] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 18:05:41] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 18:05:41] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 18:05:43] xl.utils.events INFO:  eta: 1 day, 4:14:53  iter: 19  total_loss: 399.4  time: 0.0717  data_time: 0.0243  lr: 0.0005  max_mem: 1030M
[07/09 18:05:44] xl.utils.events INFO:  eta: 1 day, 4:11:47  iter: 39  total_loss: 23.81  time: 0.0715  data_time: 0.0222  lr: 0.0005  max_mem: 1030M
[07/09 18:05:46] xl.utils.events INFO:  eta: 1 day, 4:09:06  iter: 59  total_loss: 16.76  time: 0.0710  data_time: 0.0218  lr: 0.0005  max_mem: 1030M
[07/09 18:05:47] xl.utils.events INFO:  eta: 1 day, 4:04:26  iter: 79  total_loss: 17.16  time: 0.0710  data_time: 0.0228  lr: 0.0005  max_mem: 1031M
[07/09 18:05:49] xl.utils.events INFO:  eta: 1 day, 4:05:25  iter: 99  total_loss: 16.69  time: 0.0710  data_time: 0.0220  lr: 0.0005  max_mem: 1031M
[07/09 18:05:50] xl.utils.events INFO:  eta: 1 day, 3:56:36  iter: 119  total_loss: 16.06  time: 0.0707  data_time: 0.0218  lr: 0.0005  max_mem: 1031M
[07/09 18:05:51] xl.utils.events INFO:  eta: 1 day, 3:55:38  iter: 139  total_loss: 17.79  time: 0.0706  data_time: 0.0216  lr: 0.0005  max_mem: 1031M
[07/09 18:05:53] xl.utils.events INFO:  eta: 1 day, 3:51:08  iter: 159  total_loss: 17.53  time: 0.0705  data_time: 0.0217  lr: 0.0005  max_mem: 1031M
[07/09 18:05:54] xl.utils.events INFO:  eta: 1 day, 3:49:14  iter: 179  total_loss: 17.89  time: 0.0704  data_time: 0.0217  lr: 0.0005  max_mem: 1031M
[07/09 18:05:56] xl.utils.events INFO:  eta: 1 day, 3:50:12  iter: 199  total_loss: 17.24  time: 0.0706  data_time: 0.0229  lr: 0.0005  max_mem: 1031M
[07/09 18:05:57] xl.utils.events INFO:  eta: 1 day, 3:47:25  iter: 219  total_loss: 17.58  time: 0.0705  data_time: 0.0218  lr: 0.0005  max_mem: 1031M
[07/09 18:05:59] xl.utils.events INFO:  eta: 1 day, 3:44:41  iter: 239  total_loss: 16  time: 0.0704  data_time: 0.0219  lr: 0.0005  max_mem: 1031M
[07/09 18:06:00] xl.utils.events INFO:  eta: 1 day, 3:40:46  iter: 259  total_loss: 15.98  time: 0.0703  data_time: 0.0218  lr: 0.0005  max_mem: 1031M
[07/09 18:06:01] xl.utils.events INFO:  eta: 1 day, 3:39:53  iter: 279  total_loss: 15.72  time: 0.0703  data_time: 0.0214  lr: 0.0005  max_mem: 1031M
[07/09 18:06:03] xl.utils.events INFO:  eta: 1 day, 3:39:36  iter: 299  total_loss: 17.59  time: 0.0704  data_time: 0.0226  lr: 0.0005  max_mem: 1031M
[07/09 18:06:04] xl.utils.events INFO:  eta: 1 day, 3:39:35  iter: 319  total_loss: 17.23  time: 0.0704  data_time: 0.0213  lr: 0.0005  max_mem: 1031M
[07/09 18:06:19] xmodaler INFO: Rank of current process: 0. World size: 1
[07/09 18:06:20] xmodaler INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0]
numpy                   1.19.4
detectron2              0.3 @/export1/net/imagenet/detectron2/detectron2
detectron2._C           not built correctly: /export1/net/imagenet/detectron2/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv
Compiler ($CXX)         c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA compiler           Build cuda_11.1.TC455_06.29069683_0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   GeForce GTX 1070 (arch=6.1)
CUDA_HOME               /usr/local/cuda
Pillow                  8.0.1
torchvision             0.10.0+cu111 @/home/v-yehl/.local/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.3.post20210204
iopath                  0.1.3
cv2                     4.4.0
----------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[07/09 18:06:20] xmodaler INFO: Command line arguments: Namespace(config_file='./configs/mm_understanding/vqa/vqa.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/09 18:06:20] xmodaler INFO: Contents of args.config_file=./configs/mm_understanding/vqa/vqa.yaml:
_BASE_: "../mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: ''

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 8
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 0
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23

######################################### BERT #########################################
  BERT:
    NUM_HIDDEN_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    NUM_GENERATION_LAYERS: 2

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
    POOLER_BN: False
    POOLER_DROPOUT: 0.1

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 10
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.999]
  EPS: 1e-8
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: 'value'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'StepLR'
  STEP_SIZE: 3
  GAMMA: 0.1

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False

[07/09 18:06:20] xmodaler INFO: Running with full config:
CUDNN_BENCHMARK: True
DATALOADER:
  ANNO_FOLDER: ../open_source_dataset/VQA
  FEATS_FOLDER: ../open_source_dataset/VQA/features/up_down
  MAX_FEAT_NUM: 51
  NUM_WORKERS: 0
  SEQ_PER_SAMPLE: 1
  TEST_BATCH_SIZE: 32
  TRAIN_BATCH_SIZE: 8
DATASETS:
  TEST: 
  TRAIN: VQADataset
  VAL: VQADataset
DECODE_STRATEGY:
  BEAM_SIZE: 1
  NAME: BeamSearcher
ENGINE:
  NAME: DefaultTrainer
INFERENCE:
  GENERATION_MODE: False
  ID_KEY: question_id
  NAME: VQAEvaler
  TEST_ANNFILE: 
  VALUE: answer
  VAL_ANNFILE: ../open_source_dataset/VQA/val_target.pkl
  VOCAB: 
LOSSES:
  LABELSMOOTHING: 0.1
  NAMES: ['BCEWithLogits']
LR_SCHEDULER:
  GAMMA: 0.1
  NAME: StepLR
  STEP_SIZE: 3
MODEL:
  BERT:
    ATTENTION_PROBS_DROPOUT_PROB: 0.1
    FFN_DROPOUT_PROB: 0.1
    HIDDEN_ACT: gelu
    HIDDEN_DROPOUT_PROB: 0.1
    HIDDEN_SIZE: 768
    INTERMEDIATE_DROP: 0.1
    INTERMEDIATE_SIZE: 3072
    NUM_ATTENTION_HEADS: 12
    NUM_GENERATION_LAYERS: 2
    NUM_HIDDEN_LAYERS: 2
    NUM_UNDERSTANDING_LAYERS: 2
    V_NUM_HIDDEN_LAYERS: 2
    V_TARGET_SIZE: 0
  DECODER: DecoupleBertDecoder
  DECODER_DIM: 1024
  DEVICE: cuda
  ENCODER: TwoStreamBertEncoder
  ENCODER_DIM: 1024
  MAX_SEQ_LEN: 23
  META_ARCHITECTURE: BiTransformerEncoderDecoder
  MM_PREDICTOR:
    LABELS_NUM: 3129
    POOLER_BN: False
    POOLER_DROPOUT: 0.1
    POOLER_INPUT_SIZE: 768
    POOLER_OUTPUT_SIZE: 768
  PREDICTOR: MultiModalPredictor
  PRED_DROPOUT: 0.0
  PRETRAINING:
    DO_LOWER_CASE: True
    FROM_PRETRAINED: bert-base-uncased
    MODEL_NAME: bert-base-uncased
  TOKEN_EMBED:
    ACTIVATION: none
    DIM: 768
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    NAME: TokenBaseEmbedding
    POSITION: NNEmbeddingEncoding
    POSITION_MAX_LEN: 512
    TYPE_VOCAB_SIZE: 3
    USE_NORM: True
  VISUAL_EMBED:
    ACTIVATION: none
    DROPOUT: 0.1
    ELU_ALPHA: 0.5
    IN_DIM: 2048
    LOCATION_SIZE: 5
    NAME: VisualBaseEmbedding
    OUT_DIM: 768
    USE_NORM: True
  VOCAB_SIZE: 30522
  V_PREDICTOR: 
  WEIGHTS: 
OUTPUT_DIR: ./output
SCHEDULED_SAMPLING:
  INC_EVERY_EPOCH: 5
  INC_PROB: 0.05
  MAX_PROB: 0.25
  START_EPOCH: 0
SCORER:
  CIDER_CACHED: coco_train_cider.pkl
  EOS_ID: 0
  GT_PATH: coco_train_gts.pkl
  NAME: 
  TYPES: ['']
  WEIGHTS: [1.0]
SEED: -1
SOLVER:
  AMSGRAD: False
  BASE_LR: 0.0005
  BETAS: [0.9, 0.999]
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1
  DAMPENING: 0.0
  EPOCH: 10
  EPS: 1e-08
  EVAL_PERIOD: 1
  GRAD_CLIP: 0.1
  GRAD_CLIP_TYPE: value
  MOMENTUM: 0.0
  NAME: Adam
  NESTEROV: 0.0
  NORM_TYPE: 2.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
VERSION: 1
[07/09 18:06:20] xmodaler INFO: Full config saved to ./output/config.yaml
[07/09 18:06:20] xl.utils.env INFO: Using a generated random seed 20357618
[07/09 18:06:22] xl.engine.defaults INFO: Model:
BiTransformerEncoderDecoder(
  (token_embed): TokenBaseEmbedding(
    (embeddings): Embedding(30522, 768)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): NNEmbeddingEncoding(
      (position_embeddings): Embedding(512, 768)
    )
    (embeddings_token_type): Embedding(3, 768)
  )
  (visual_embed): VisualBaseEmbedding(
    (embeddings): Linear(in_features=2048, out_features=768, bias=True)
    (embeddings_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embeddings_dropout): Dropout(p=0.1, inplace=False)
    (embeddings_pos): Linear(in_features=5, out_features=768, bias=True)
  )
  (encoder): TwoStreamBertEncoder(
    (layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (v_layers): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (decoder): DecoupleBertDecoder(
    (u_layers): ModuleList(
      (0): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertUnderstandingLayer(
        (biattention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (v_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (t_output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (g_layers): ModuleList(
      (0): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertGenerationLayer(
        (self_attn): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (x_att): BertCrossAttention(
          (self): BertXAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (predictor): MultiModalPredictor(
    (u_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (v_pooler): ModuleList(
      (0): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
      (1): AttentionPooler(
        (att): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=768, out_features=1, bias=True)
        )
        (embed): Linear(in_features=768, out_features=768, bias=True)
        (softmax): Softmax(dim=-1)
      )
    )
    (u_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
    (g_pooler): AttentionPooler(
      (att): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=768, out_features=1, bias=True)
      )
      (embed): Linear(in_features=768, out_features=768, bias=True)
      (softmax): Softmax(dim=-1)
    )
    (g_logits): Sequential(
      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=768, out_features=3129, bias=True)
    )
  )
  (greedy_decoder): GreedyDecoder()
  (beam_searcher): BeamSearcher()
)
[07/09 18:06:25] xl.datasets.common INFO: Serializing 1146920 elements to byte tensors and concatenating them all ...
[07/09 18:06:29] xl.datasets.common INFO: Serialized dataset takes 170.64 MiB
[07/09 18:06:29] xl.datasets.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[07/09 18:06:29] xl.datasets.common INFO: Serialized dataset takes 0.46 MiB
[07/09 18:06:32] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[07/09 18:06:32] xl.engine.train_loop INFO: Starting training from iteration 0
[07/09 18:06:50] xl.engine.hooks INFO: ############################## val_0 ##############################
[07/09 18:06:59] xl.engine.hooks INFO: accuracy: 0.0
