NoamLR            noam_lr.py
MultiStepLR       lr_scheduler.MultiStepLR

warmup_constant   warmup_lr.WarmupConstantSchedule
warmup_linear     warmup_lr.WarmupLinearSchedule
warmup_cosine     warmup_lr.WarmupCosineSchedule
warmup_multistep  warmup_lr.WarmupMultiStepLR


        if lr_policy.TYPE == 'Fix':
            self.scheduler = None
        elif lr_policy.TYPE == 'Step':
            self.scheduler = torch.optim.lr_scheduler.StepLR(
                self.optimizer, 
                step_size = lr_policy.STEP_SIZE, 
                gamma = lr_policy.GAMMA
            )
        elif lr_policy.TYPE == 'MultiStep':
            self.scheduler = lr_scheduler.create(
                'MultiStep', 
                self.optimizer,
                milestones = lr_policy.STEPS,
                gamma = lr_policy.GAMMA
            )
        elif lr_policy.TYPE == 'Noam':
            self.scheduler = lr_scheduler.create(
                'Noam', 
                self.optimizer,
                model_size = lr_policy.MODEL_SIZE,
                factor = 1.0,
                warmup = warmup_steps,
            )
        elif lr_policy.TYPE == 'warmup_constant':
            self.scheduler = warmup_lr.WarmupConstantSchedule(
                self.optimizer, 
                warmup_steps=warmup_steps)
        elif lr_policy.TYPE == 'warmup_linear':
            self.scheduler = warmup_lr.WarmupLinearSchedule(
                self.optimizer, 
                min_lr=min_lr/base_lr,
                warmup_steps=warmup_steps,
                t_total=n_steps)
        elif lr_policy.TYPE == 'warmup_cosine':
            self.scheduler = warmup_lr.WarmupCosineSchedule(
                self.optimizer, 
                min_lr=min_lr/base_lr,
                warmup_steps=warmup_steps,
                t_total=n_steps)
        elif lr_policy.TYPE == 'warmup_multistep':
            steps = [step * step_per_epoch for step in lr_policy.STEPS]
            self.scheduler = warmup_lr.WarmupMultiStepLR(
                self.optimizer,
                milestones=steps,
                gamma=lr_policy.GAMMA,
                warmup_factor=0,
                warmup_iters=warmup_steps,
                warmup_method="linear",
            )
